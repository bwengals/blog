<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>how-to-fit-a-gp – Bill Engels's Web Log</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Bill Engels’s Web Log</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/bwengals"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<div id="7830f455-4420-4d96-be23-5a90a6565fb3" class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>title: <span class="st">"My Post"</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>description: <span class="st">"Post description"</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>author: <span class="st">"Fizz McPhee"</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>date: <span class="st">"5/22/2021"</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>draft: true</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="op">---</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="a4af8ca6-98ff-4ea2-8a5a-f9186b9c6b7c" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pytensor.tensor <span class="im">as</span> pt</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nutpie</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>RANDOM_SEED <span class="op">=</span> <span class="dv">8998</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(RANDOM_SEED)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="intro" class="level1">
<h1>Intro</h1>
<p>In a lot of Bayesian models you can more often than not get away with using weakly informative priors without dwelling on the details too much. Often you’ll set priors like Gaussians with large variances for regression coeficients, or half-normals for standard deviation parameters, and you can trust that your model will give reasonable results. With GPs this isn’t the case. You’ll have to pause and think a little more carefully about it for every model, particularly for the lengthscale parameter. There’s a good amount of papers written about the topic so it’s best to stick with what the research has found to work well, instead of trying to come up with your own lengthscale priors on the spot.</p>
<p>The long story short is that the <em>inverse gamma</em> distribution is a great all-purpose choice (<code>pm.InverseGamma</code>). I doubt that for TVP’s you’ll need to use a different distribution. We also need to take a lot of care in how we parameterize it, that matters even more than the choice of distribution. Fortunately, it doesn’t require a ton of math to motivate this choice and understand the failure modes and it’s really not that complicated once you walk through it, which we’ll do next.</p>
<section id="the-lengthscale-prior-is-important" class="level2">
<h2 class="anchored" data-anchor-id="the-lengthscale-prior-is-important">The lengthscale prior is important</h2>
<p>Before getting into, I want to show how using uninformative / bad lengthscale priors can cause problems. To demonstrate this, I’ll draw some prior samples from a GP where the lengthscale has a uniform prior from 0 to 100, and the x data is daily, going from 0 to 100 days.</p>
<p>What happens under the hood is: 1. Draw one sample from the lengthscale prior 2. Plug that into the covariance function 3. Calculate the covariance matrix over all pairs of x 4. Draw one sample from a multivariate normal with that covariance matrix 5. Repeat</p>
<p>So each of the samples below is a sample with a different lengthscale.</p>
<div id="6f7a2dc1-093e-420c-a252-ed987c487f65" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(<span class="dv">100</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>ell <span class="op">=</span> pm.Uniform.dist(lower<span class="op">=</span><span class="fl">0.0</span>, upper<span class="op">=</span><span class="fl">100.0</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>cov <span class="op">=</span> pm.gp.cov.Matern52(<span class="dv">1</span>, ls<span class="op">=</span>ell)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> pm.draw(pm.MvNormal.dist(mu<span class="op">=</span>np.zeros(<span class="bu">len</span>(x)), cov<span class="op">=</span>cov(x[:, <span class="va">None</span>])), draws<span class="op">=</span>n_samples, random_seed<span class="op">=</span>rng)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>ax.plot(x, s.T)<span class="op">;</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>ax.set_xlim([<span class="dv">0</span>, <span class="dv">100</span>])<span class="op">;</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"x"</span>)<span class="op">;</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="ss">f"</span><span class="sc">{</span>n_samples<span class="sc">}</span><span class="ss"> samples from a GP with $\ell \sim U(0, 100)$"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-4-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>These are look <em>very</em> different, in terms of wiggliness. Some of the samples from the GP change very slowly and some change very rapidly. Unless you’re really fishing, you probably already know quite a bit about the rate at which changes are happening. TikTok may make substantive or relevant changes to their algorithm on roughly a monthly time scale, instead of annual, or by the minute. A particular ad campaign may run for a few weeks at a minimum. These sorts of insights help put priors on the lengthscale (which has units as x).</p>
<p>If you stare at it a while, you might also notice that there are a lot more very smooth, slowly varying lines than there are wiggly, quickly changing lines. This is because <strong>a uniform prior on the the lengthscale doesn’t translate to uniform “wiggliness”</strong>. This is why the uniform prior isn’t a good prior. We can’t quantify the wiggliness of each sample by calculating the number of zero crossings of each sample. A very smooth sample may cross zero once, or not at all. A very wiggly sample will cross zero many times. I think the number of zero crossings is a better measure for how wiggly a function appears to be. Keep in mind that the number of zero crossings will of course depend on the domain of x. In this case x runs from 0 to 50 days.</p>
<div id="6c83e876-24c8-4393-a420-289891740b30" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">1000</span> <span class="co"># draw 1000 samples from a GP with the uniform lengthscale</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> pm.draw(pm.MvNormal.dist(mu<span class="op">=</span>np.zeros(<span class="bu">len</span>(x)), cov<span class="op">=</span>cov(x[:, <span class="va">None</span>])), draws<span class="op">=</span>n_samples, random_seed<span class="op">=</span>rng)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>zcs <span class="op">=</span> (np.diff(np.sign(s), axis<span class="op">=</span><span class="dv">1</span>) <span class="op">!=</span> <span class="dv">0</span>).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>) <span class="co"># calculate zero crossings of each sample</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>plt.hist(zcs, bins<span class="op">=</span>np.arange(<span class="dv">50</span>))<span class="op">;</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Number of zero crossings in 50 days"</span>)<span class="op">;</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Number of GP samples"</span>)<span class="op">;</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Count of zero crossings, Unif(0, 100) prior"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We can clearly see that the number of zero crossings is strongly skewed towards zero. So gradually, slowly changing samples are strongly represented. The point of this was to show that while lengthscale controls wiggliness, it doesn’t equal it. If it did, we might expect a uniform prior on lengthscale to give us a uniform distribution of zero crossings, but that clearly isn’t the case.</p>
<p>Before moving on, let’s try out the inverse gamma prior we said at the beginning was the best. Imagine we’re roughly aiming for weekly variation, maybe because new products are introduced every week. Let’s set a prior on the lengthscale that’s inverse gamma, where 90% of the prior mass is between 5 and 10, to roughly give us weekly variation. We can use the built-in function <code>pm.set_constrained_prior</code> to help us do that.</p>
<div id="7aa3dbe2-1b2f-4206-babb-f4af626be4cf" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># why inverse gamma rather than normal </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="c3434423-f38c-4b3b-bb47-4cd40534140a" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>pm.find_constrained_prior(</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    pm.Normal,</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    lower<span class="op">=</span><span class="dv">4</span>, upper<span class="op">=</span><span class="dv">11</span>, mass<span class="op">=</span><span class="fl">0.95</span>,</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    init_guess<span class="op">=</span>{<span class="st">"mu"</span>: <span class="dv">7</span>, <span class="st">"sigma"</span>: <span class="dv">2</span>},</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>{'mu': 7.499959574903695, 'sigma': 1.7857473928234064}</code></pre>
</div>
</div>
<div id="ebafeffd-e018-4058-980c-e30993e50e58" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>ell_params <span class="op">=</span> pm.find_constrained_prior(</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    pm.InverseGamma,</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    lower<span class="op">=</span><span class="dv">4</span>, upper<span class="op">=</span><span class="dv">11</span>, mass<span class="op">=</span><span class="fl">0.95</span>,</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    init_guess<span class="op">=</span>{<span class="st">"mu"</span>: <span class="dv">7</span>, <span class="st">"sigma"</span>: <span class="dv">2</span>},</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>ell <span class="op">=</span> pm.InverseGamma.dist(<span class="op">**</span>ell_params) </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>cov <span class="op">=</span> pm.gp.cov.Matern52(<span class="dv">1</span>, ls<span class="op">=</span>ell)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> pm.draw(pm.MvNormal.dist(mu<span class="op">=</span>np.zeros(<span class="bu">len</span>(x)), cov<span class="op">=</span>cov(x[:, <span class="va">None</span>])), draws<span class="op">=</span>n_samples, random_seed<span class="op">=</span>rng)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>zcs <span class="op">=</span> (np.diff(np.sign(s), axis<span class="op">=</span><span class="dv">1</span>) <span class="op">!=</span> <span class="dv">0</span>).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>) <span class="co"># calculate zero crossings of each sample</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>plt.hist(zcs, bins<span class="op">=</span>np.arange(<span class="dv">20</span>))<span class="op">;</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Number of zero crossings in 50 days"</span>)<span class="op">;</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Number of GP samples"</span>)<span class="op">;</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>plt.xticks(np.arange(<span class="dv">20</span>))<span class="op">;</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Count of zero crossings, InverseGamma prior"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>It’s not a uniform prior, but it does center pretty nicely around 7, and the width of the distribution looks reasonable too. Three zero crossings in 50 days corresponds roughly to a zero crossing every 16 days, and 12 zero crossings in 50 days corresponds roughly to a zero crossing every 4 days. This GP should be aimed at weekly, but still be flexible enough to adapt to the data. It won’t be able to consider daily or monthly variation.</p>
<p><font color="blue">Below are some samples with the inverse gamma lengthscale prior. To the eye the variation for all the samples looks like it happens on weekly scales but there’s still a ton of freedom to fit different trends or patterns, as long they happen on a weekly scale.</font></p>
<div id="fec068ea-4c3b-4b32-a407-740ba4ae7141" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># KATE </span><span class="al">NOTE</span><span class="co">: try tweaking these and get a simple gp to git </span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Try dummy data </span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>ax.plot(x, s[np.arange(<span class="dv">25</span>), :].T)<span class="op">;</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>ax.set_xlim([<span class="dv">0</span>, <span class="dv">100</span>])<span class="op">;</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"x"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-9-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The takeaway is that the best overarching principle for setting the lengthscale prior is to be as informative as possible. The point if this example is to show that if the lengthscale is allowed to float freely, GPs are really flexible, <font color="blue">and the lengthscale doesn’t equally weight smooth and wiggly functions. In fact, it’s a bit counterintuitive, but by using a uniform prior on the lengthscale you’re actually using a very informative prior that heavily weights flat or nearly flat GPs. The best approach is to take a bit of time to come up with an informative prior for the lengthscale.</font></p>
</section>
<section id="how-to-set-informative-priors" class="level2">
<h2 class="anchored" data-anchor-id="how-to-set-informative-priors">How to set informative priors</h2>
<p>My favorite way to do this is with tail probabilities because I find them easier to think about. To me, it’s more meaningful to say, “95% of the lengthscale mass is between 1 and 5”, instead of “the mean of the lengthscale is 2, and the standard deviation is 2”. With the first statement, you’re saying that you think that it’s really unlikely that the lengthscale is smaller than 1 or larger than 5. In the second, you’re conveying a sense of where you think the lengthscale should be located, and then setting the uncertainty around that. Even if these two statements were to be equivalent, by setting tail probabilities you’re ruling values out, instead of preferring some values over others.</p>
<p>You can do this in PyMC with the utility function <code>pm.find_constrained_prior</code>.</p>
<div id="1bb7ae19-7415-4a82-a5a4-a224ca53736e" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>pm.find_constrained_prior(</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    pm.Normal,</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    lower<span class="op">=</span><span class="dv">1</span>, upper<span class="op">=</span><span class="dv">5</span>, mass<span class="op">=</span><span class="fl">0.95</span>,</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    init_guess<span class="op">=</span>{<span class="st">"mu"</span>: <span class="dv">2</span>, <span class="st">"sigma"</span>: <span class="dv">1</span>},</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>{'mu': 2.2321082679792026, 'sigma': 0.7485883342665849}</code></pre>
</div>
</div>
<p>You may notice it’ll fail to converge if you use too narrow of a range for inverse gammas,</p>
<div id="0041fdfa-f707-4199-a3df-42baed3e5489" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>pm.find_constrained_prior(</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    pm.InverseGamma,</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    lower<span class="op">=</span><span class="dv">3</span>, upper<span class="op">=</span><span class="dv">5</span>, mass<span class="op">=</span><span class="fl">0.95</span>,</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    init_guess<span class="op">=</span>{<span class="st">"mu"</span>: <span class="dv">2</span>, <span class="st">"sigma"</span>: <span class="dv">1</span>},</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ValueError</span>                                Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[9], line 1</span>
<span class="ansi-green-fg">----&gt; 1</span> <span class="ansi-yellow-bg">pm</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">find_constrained_prior</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-fg ansi-bold">      2</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">pm</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">InverseGamma</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">      3</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">lower</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">3</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">upper</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">5</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">mass</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">0.95</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">      4</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">init_guess</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">{</span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">"</span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">mu</span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">"</span><span class="ansi-yellow-bg">:</span><span class="ansi-yellow-bg"> </span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">2</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">"</span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">sigma</span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">"</span><span class="ansi-yellow-bg">:</span><span class="ansi-yellow-bg"> </span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">1</span><span class="ansi-yellow-bg">}</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">      5</span> <span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/miniforge3/envs/techstyle/lib/python3.11/site-packages/pymc/func_utils.py:187</span>, in <span class="ansi-cyan-fg">find_constrained_prior</span><span class="ansi-blue-fg">(distribution, lower, upper, init_guess, mass, fixed_params, mass_below_lower, **kwargs)</span>
<span class="ansi-green-fg ansi-bold">    183</span> opt <span style="color:rgb(98,98,98)">=</span> optimize<span style="color:rgb(98,98,98)">.</span>minimize(
<span class="ansi-green-fg ansi-bold">    184</span>     target_fn, x0<span style="color:rgb(98,98,98)">=</span><span style="color:rgb(0,135,0)">list</span>(init_guess<span style="color:rgb(98,98,98)">.</span>values()), jac<span style="color:rgb(98,98,98)">=</span>jac, constraints<span style="color:rgb(98,98,98)">=</span>cons, <span style="color:rgb(98,98,98)">*</span><span style="color:rgb(98,98,98)">*</span>kwargs
<span class="ansi-green-fg ansi-bold">    185</span> )
<span class="ansi-green-fg ansi-bold">    186</span> <span style="font-weight:bold;color:rgb(0,135,0)">if</span> <span style="font-weight:bold;color:rgb(175,0,255)">not</span> opt<span style="color:rgb(98,98,98)">.</span>success:
<span class="ansi-green-fg">--&gt; 187</span>     <span style="font-weight:bold;color:rgb(0,135,0)">raise</span> <span style="font-weight:bold;color:rgb(215,95,95)">ValueError</span>(
<span class="ansi-green-fg ansi-bold">    188</span>         <span style="color:rgb(175,0,0)">f</span><span style="color:rgb(175,0,0)">"</span><span style="color:rgb(175,0,0)">Optimization of parameters failed.</span><span style="font-weight:bold;color:rgb(175,95,0)">\n</span><span style="color:rgb(175,0,0)">Optimization termination details:</span><span style="font-weight:bold;color:rgb(175,95,0)">\n</span><span style="font-weight:bold;color:rgb(175,95,135)">{</span>opt<span style="font-weight:bold;color:rgb(175,95,135)">}</span><span style="color:rgb(175,0,0)">"</span>
<span class="ansi-green-fg ansi-bold">    189</span>     )
<span class="ansi-green-fg ansi-bold">    191</span> <span style="font-style:italic;color:rgb(95,135,135)"># save optimal parameters</span>
<span class="ansi-green-fg ansi-bold">    192</span> opt_params <span style="color:rgb(98,98,98)">=</span> {
<span class="ansi-green-fg ansi-bold">    193</span>     param_name: param_value <span style="font-weight:bold;color:rgb(0,135,0)">for</span> param_name, param_value <span style="font-weight:bold;color:rgb(175,0,255)">in</span> <span style="color:rgb(0,135,0)">zip</span>(init_guess<span style="color:rgb(98,98,98)">.</span>keys(), opt<span style="color:rgb(98,98,98)">.</span>x)
<span class="ansi-green-fg ansi-bold">    194</span> }

<span class="ansi-red-fg">ValueError</span>: Optimization of parameters failed.
Optimization termination details:
 message: Iteration limit reached
 success: False
  status: 9
     fun: 0.0014422914420487301
       x: [ 3.961e+00  7.141e-01]
     nit: 100
     jac: [-1.901e-02  2.360e-02]
    nfev: 1042
    njev: 100</pre>
</div>
</div>
</div>
<p>When this happens, I’ll usually switch to <code>pm.LogNormal</code>. It’s a similarly shaped distribution to the inverse gamma, but it’s a bit suboptimal as a lengthscale prior because it doesn’t penalize small values as much as the inverse gamma. However, if you’re prior is so strong that the inverse gamma doesn’t work, small lengthscales won’t be a problem.</p>
<div id="a076ddef-b0cd-4c25-bf22-f20a9cebc507" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>pm.find_constrained_prior(</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    pm.LogNormal,</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    lower<span class="op">=</span><span class="dv">3</span>, upper<span class="op">=</span><span class="dv">5</span>, mass<span class="op">=</span><span class="fl">0.95</span>,</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    init_guess<span class="op">=</span>{<span class="st">"mu"</span>: <span class="dv">2</span>, <span class="st">"sigma"</span>: <span class="fl">0.2</span>},</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>{'mu': 1.354045683682159, 'sigma': 0.13031529959654345}</code></pre>
</div>
</div>
</section>
<section id="lengthscale-too-small" class="level2">
<h2 class="anchored" data-anchor-id="lengthscale-too-small">Lengthscale too small</h2>
<p>Often, it’s not enought to just be more informative. There are cases where the GP will just fail to work due to how the lengthscale prior was set. We’ll start with the case when the lengthscale is too small. This case is a bit more cut and dry than the situation when the lengthscale is too large. It might be somewhat obvious, but for your case <strong>with daily x data, you wont be able to see variation that happens faster than daily</strong> (and you probably don’t care about it anyway). Here’s an example. We’ll draw samples from a GP prior, but we’ll lower the lengthscale below the resolution of the data and see what happens.</p>
<p>Before actually seeing the example, it’s helpful to know that you can think of a GP as smoothing a sample of random Gaussian noise using a kernel, just like a <a href="https://en.wikipedia.org/wiki/Kernel_density_estimation">kernel density esimator</a>. We’ll use that fact in the example to smooth a single sample of Gaussian noise with the set of different different lengthscales. I like doing it this way because it makes each sample directly comparable to the others.</p>
<div id="28abf8a0-a136-44f5-aed9-03451774d9d7" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">50</span> <span class="co"># number of days of data</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(n)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>lengthscales <span class="op">=</span> [<span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">1.0</span>, <span class="fl">1.5</span>, <span class="fl">2.0</span>, <span class="fl">3.0</span>, <span class="fl">5.0</span>, <span class="fl">6.0</span>]</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="bu">len</span>(lengthscales))</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co"># draw a sample of random noise</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> rng.normal(size<span class="op">=</span>n)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, ell <span class="kw">in</span> <span class="bu">enumerate</span>(lengthscales):</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    cov <span class="op">=</span> pm.gp.cov.Matern52(input_dim<span class="op">=</span><span class="dv">1</span>, ls<span class="op">=</span>ell)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    K <span class="op">=</span> cov(x[:, <span class="va">None</span>]).<span class="bu">eval</span>()</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    L <span class="op">=</span> np.linalg.cholesky(K <span class="op">+</span> <span class="fl">1e-6</span> <span class="op">*</span> np.eye(n))</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    f <span class="op">=</span> L <span class="op">@</span> z</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>    ax.plot(x, f, color<span class="op">=</span>plt.cm.viridis(colors[i]), label<span class="op">=</span><span class="ss">f"$\ell=</span><span class="sc">{</span>ell<span class="sc">}</span><span class="ss">$"</span>)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> ax.plot(x, z, color<span class="op">=</span><span class="st">"k"</span>, label<span class="op">=</span><span class="st">"z"</span>)<span class="op">;</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="st">"upper left"</span>)<span class="op">;</span></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>ax.set_xlim([<span class="op">-</span><span class="dv">6</span>, n])<span class="op">;</span></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"day"</span>)<span class="op">;</span></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"Draws from GP prior"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-13-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>You can see big changes in the curve at larger lengthscales, until you get down to lengthscales below a day. At <span class="math inline">\(\ell \leq 1\)</span>, they start to blur together until finally the lengthscale is small enough that no smoothing happens to <code>z</code> and you get <code>z</code> back as it was (shown as the black line).</p>
<p>Imagine you put a prior on <span class="math inline">\(\ell\)</span> that had all of it’s mass between zero and one. This is functionally the same as adding normal distribution prior to every day of your data – which probably isn’t what you want to do. What your prior is saying is that there is no relationship between the values of the TVP on successive days, so there’s no smoothing happening.</p>
<p>A good lengthscale prior will have a pretty hard cutoff on low values of the lengthscale, especially below the resolution of the data. This is one reason that makes the inverse gamma a good probability distribution to use. It’s shown against a few other distributions below.</p>
<div id="db58ed9c-5d87-46eb-b456-6ec5c955fad3" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> pm.draw(pm.InverseGamma.dist(mu<span class="op">=</span><span class="fl">2.5</span>, sigma<span class="op">=</span><span class="dv">1</span>), <span class="dv">20_000</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>plt.hist(s, np.linspace(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">100</span>), color<span class="op">=</span><span class="st">"slateblue"</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, label<span class="op">=</span><span class="st">"inverse gamma"</span>)<span class="op">;</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> pm.draw(pm.Lognormal.dist(mu<span class="op">=</span><span class="fl">0.8</span>, sigma<span class="op">=</span><span class="fl">0.4</span>), <span class="dv">20_000</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>plt.hist(s, np.linspace(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">100</span>), color<span class="op">=</span><span class="st">"r"</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, label<span class="op">=</span><span class="st">"log-normal"</span>)<span class="op">;</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> pm.draw(pm.HalfNormal.dist(sigma<span class="op">=</span><span class="dv">2</span>), <span class="dv">20_000</span>)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>plt.hist(s, np.linspace(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">100</span>), color<span class="op">=</span><span class="st">"orange"</span>, alpha<span class="op">=</span><span class="fl">0.2</span>, label<span class="op">=</span><span class="st">"half-normal"</span>)<span class="op">;</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> pm.draw(pm.TruncatedNormal.dist(mu <span class="op">=</span> <span class="fl">2.5</span>, sigma<span class="op">=</span><span class="dv">1</span>, lower<span class="op">=</span><span class="dv">1</span>), <span class="dv">20_000</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>plt.hist(s, np.linspace(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">100</span>), color<span class="op">=</span><span class="st">"g"</span>, alpha<span class="op">=</span><span class="fl">0.2</span>, label<span class="op">=</span><span class="st">"truncated-normal"</span>)<span class="op">;</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># x = pm.TruncatedNormal('x', mu=0, sigma=10, lower=0)</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>ax.set_yticks([])<span class="op">;</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>ax.set_xlim([<span class="dv">0</span>, <span class="dv">5</span>])<span class="op">;</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"x"</span>)<span class="op">;</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>ax.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-14-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>You can see from the picture that for the particular values of the prior, the inverse gamma has a pretty hard cutoff for values below 1. The log-normal isn’t as strong there and the half-normal peaks at zero.</p>
</section>
<section id="large-lengthscales" class="level2">
<h2 class="anchored" data-anchor-id="large-lengthscales">Large lengthscales</h2>
<p>A large lengthscale isn’t inherently a problem. Sometimes you want to allow large lengthscales. Two issues will likely arise though:</p>
<ol type="1">
<li>The GP starts to look a lot like other components that you may already have in your model, particularly the intercept. When the lengthscale is very large, the GP will model flat lines at varying heights, which is exactly what an intercept is.</li>
<li>We don’t see enough “repetitions” or cycles of the GP to be able to learn the value of lengthscale. This can cause poor sampling performance. In this case, you need to compensate by either using a very informative prior, or using a simpler component in your model, like a linear trend. It may make sense in some cases to fix the lengthscale value to a large number, especially if it’s something larger than the domain of the data.</li>
</ol>
<p>To see what an illustration, below are 10 samples from a GP with a long lengthscale.</p>
<div id="005cfef6-0c96-41c4-b327-d45d52bc6721" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co">## plot long lengthscale GP samples</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(<span class="dv">100</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>eta <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>ell_long <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>cov <span class="op">=</span> eta<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> pm.gp.cov.Matern52(<span class="dv">1</span>, ls<span class="op">=</span>ell_long)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> pm.draw(pm.MvNormal.dist(mu<span class="op">=</span>np.zeros(<span class="bu">len</span>(x)), cov<span class="op">=</span>cov(x[:, <span class="va">None</span>])), n_samples, random_seed<span class="op">=</span>rng)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>ax.plot(x, s.T, color<span class="op">=</span><span class="st">"slateblue"</span>, lw<span class="op">=</span><span class="dv">3</span>)<span class="op">;</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>ax.set_xlim([<span class="dv">0</span>, <span class="dv">100</span>])<span class="op">;</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"x"</span>)<span class="op">;</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="ss">f"</span><span class="sc">{</span>n_samples<span class="sc">}</span><span class="ss"> samples from a GP with $\ell = </span><span class="sc">{</span>ell_long<span class="sc">}</span><span class="ss">$"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-15-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>These samples are all <em>almost</em> flat, or at best linear. Since the intercept is (usually) used to fit the mean of the data, you need to be careful if you have an intercept adding to a GP in your model. If you have two terms additive terms in your model that are doing the same thing, you’ll get identifiabilty issues. If your lengthscale is small this isn’t an issue.</p>
<p>The scale parameter, <code>eta</code>, also comes into play here. You’ll notice in the plot above, we set <code>eta = 1</code>. All the flattish GP samples are all hanging around between -1.5 and 1.5. If you were trying to fit data whose average value was 100 it would be less problematic to have a long lengthscale GP and an intercept together, because the GP and the intercept will be identifiable together.</p>
<p>It’s tricky because knowing what’s happening with the GP and how it interacts with the other parameters in your model, depends on the values of the scale <code>eta</code> and lengthscale <code>ell</code> – which change during sampling. You have to use your priors to steer things.</p>
</section>
<section id="example-fitting-slowly-varying-data" class="level2">
<h2 class="anchored" data-anchor-id="example-fitting-slowly-varying-data">Example: fitting slowly varying data</h2>
<p>We’ll take one of the samples above, and use it to generate data.</p>
<div id="928f7be2-f7e9-4006-a432-f41df0254c63" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>sigma_true <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>f_true <span class="op">=</span> s[<span class="op">-</span><span class="dv">1</span>, :]</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> f_true <span class="op">+</span> sigma_true <span class="op">*</span> rng.normal(size<span class="op">=</span><span class="bu">len</span>(f_true))</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.mean(f_true))</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>ax.plot(x, f_true)<span class="op">;</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>ax.scatter(x, y, color<span class="op">=</span><span class="st">"c"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.29988853635817775</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-16-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="5e1f4ae7-f086-4c1c-97c9-d0e867b07f35" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>pm.find_constrained_prior(</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    pm.InverseGamma,</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    lower<span class="op">=</span><span class="dv">50</span>, upper<span class="op">=</span><span class="dv">500</span>, mass<span class="op">=</span><span class="fl">0.95</span>,</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    init_guess<span class="op">=</span>{<span class="st">"mu"</span>: <span class="fl">300.0</span>, <span class="st">"sigma"</span>: <span class="fl">200.0</span>},</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>{'mu': 221.26696046910808, 'sigma': 165.25644413979444}</code></pre>
</div>
</div>
<p>I’m going to do my best to put a decent prior on this from just looking at the data – pretending that we didn’t just it. I’ll walk through the reasoning I’m using. We’ll see that there are still issues sampling.</p>
<ol type="1">
<li>The lengthscale is definitely not smaller than say 60 or 75. I’d be suprised if it was less than 100 really. To be safe I’ll set a lower limit at 80, and say I think theres a 5% chance it’s between 50 and 500.</li>
<li>The lengthscale could be really long, it could be in the hundreds. With only a hundred days of data, we don’t see any repetitions or cycles of the function to know much at all about the lengthscale. I’ll be conservative again and say there’s a 5% chance it’s bigger than 500.</li>
<li>I’m setting the value of <code>ell</code> in the code to be between 0.7 and 5.0, and then multiplying it by 100. <code>pm.find_constrained_prior</code> can sometimes have issues when the distribution has “weird” ranges for it’s support, so it helps to keep things down near zero-ish.</li>
<li>The scale <code>eta</code> becomes harder to estimate here too, because we don’t know if the GP will keep decreasing which will give it a huge range, or if it’s just about to head back up, making a smaller <code>eta</code> work. I’m going to give it an <code>pm.Exponential</code> prior with a 10% change that <code>eta</code> is greater than 3, again just to be safe. The scale <code>eta</code> has the same units as the <code>y</code> dimension of the GP. It’s analogous to the standard deviation parameter of a univariate normal distribution. This is why we always square it, setting the covariance matrix as <code>eta**2 * pm.gp.cov.Matern52(...)</code>.</li>
<li>Just looking at the data, it’s easy to guess the intercept. In more complicated models it isn’t possible to do this, so to allow for that I’ll say that it’s a normal with mean zero and standard deviation equal to five.</li>
<li>Finally, the additive noise is pretty small, so I’ll use another <code>pm.Exponential</code> distribution with <code>scale = 1.0</code>. This is the median, so I’m also saying that <span class="math inline">\(p(\sigma &gt; 1.0) = 0.5\)</span> with my prior.</li>
</ol>
</section>
<section id="a-couple-notes" class="level2">
<h2 class="anchored" data-anchor-id="a-couple-notes"><strong>A COUPLE NOTES</strong></h2>
<ul>
<li><p>I like to use <code>pm.Exponential</code> distributions for scale priors, like <code>sigma</code> and <code>eta</code>, because it’s the <a href="https://projecteuclid.org/journals/statistical-science/volume-32/issue-1/Penalising-Model-Component-Complexity--A-Principled-Practical-Approach-to/10.1214/16-STS576.full">PC prior for a normal random effect</a>, and I find it works well in practice. <code>pm.HalfNormal</code>, <code>pm.HalfStudentT</code>, or <code>pm.HalfCauchy</code> priors <a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations#prior-for-scale-parameters-in-hierarchical-models">can work well too</a>. If you know for sure that there’s a GP there, you can try a <code>pm.Gamma</code> distribution, which is like an <code>pm.Exponential</code> but avoids zero. This choice usually isn’t nearly as important as the lengthscale prior.</p></li>
<li><p>I’m skipping ahead and using the HSGP approximation here, just for faster sampling. We’ll save how to set <code>m</code> and <code>c</code> for another discussion, because they are specific to the HSGP approximation, not GPs. You can try commenting it out and replacing it with <code>pm.gp.Latent</code>. The sampling will be much slower, but you don’t have to mess with <code>m</code> or <code>c</code>.</p></li>
</ul>
<div id="9db6ab71-29cc-4d92-9067-4f055e5e185a" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># p(eta &gt; U) = alpha</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    alpha, U <span class="op">=</span> <span class="fl">0.1</span>, <span class="fl">3.0</span> </span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    eta <span class="op">=</span> pm.Exponential(<span class="st">"eta"</span>, lam<span class="op">=-</span>np.log(alpha) <span class="op">/</span> U)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    ell <span class="op">=</span> pm.InverseGamma(</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">"ell"</span>,</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>        <span class="op">**</span>pm.find_constrained_prior(</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>            pm.InverseGamma,</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>            lower<span class="op">=</span><span class="dv">50</span>, upper<span class="op">=</span><span class="dv">500</span>, mass<span class="op">=</span><span class="fl">0.95</span>,</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>            init_guess<span class="op">=</span>{<span class="st">"mu"</span>: <span class="fl">100.0</span>, <span class="st">"sigma"</span>: <span class="fl">50.0</span>},</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>    cov_func <span class="op">=</span> eta<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> pm.gp.cov.Matern52(input_dim<span class="op">=</span><span class="dv">1</span>, ls<span class="op">=</span>ell)</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">#gp = pm.gp.Latent(cov_func=cov_func) # use this instead of pm.gp.HSGP for an unapproximated GP</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    gp <span class="op">=</span> pm.gp.HSGP(m<span class="op">=</span>[<span class="dv">200</span>], c<span class="op">=</span><span class="fl">10.0</span>, cov_func<span class="op">=</span>cov_func)</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    intercept <span class="op">=</span> pm.Normal(<span class="st">"intercept"</span>, mu<span class="op">=</span><span class="fl">0.0</span>, sigma<span class="op">=</span><span class="fl">5.0</span>)</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>    f <span class="op">=</span> gp.prior(<span class="st">"f"</span>, X<span class="op">=</span>x[:, <span class="va">None</span>])</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> pm.Deterministic(<span class="st">"mu"</span>, intercept <span class="op">+</span> f)</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> pm.Exponential(<span class="st">"sigma"</span>, scale<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>    pm.Normal(<span class="st">"y"</span>, mu<span class="op">=</span>mu, sigma<span class="op">=</span>sigma, observed<span class="op">=</span>y)</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>cmodel <span class="op">=</span> nutpie.compile_pymc_model(model, backend<span class="op">=</span><span class="st">"jax"</span>, gradient_backend<span class="op">=</span><span class="st">"jax"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.</code></pre>
</div>
</div>
<div id="cb905e7e-216b-4a6e-8a0c-2c7c78e5a789" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>sampler <span class="op">=</span> nutpie.sample(</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    compiled_model<span class="op">=</span>cmodel,</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    blocking<span class="op">=</span><span class="va">False</span>, <span class="co"># allow us to make changes to the notebook while the sampler is running</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    :root {
        --column-width-1: 40%; /* Progress column width */
        --column-width-2: 15%; /* Chain column width */
        --column-width-3: 15%; /* Divergences column width */
        --column-width-4: 15%; /* Step Size column width */
        --column-width-5: 15%; /* Gradients/Draw column width */
    }

    .nutpie {
        max-width: 800px;
        margin: 10px auto;
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        //color: #333;
        //background-color: #fff;
        padding: 10px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        border-radius: 8px;
        font-size: 14px; /* Smaller font size for a more compact look */
    }
    .nutpie table {
        width: 100%;
        border-collapse: collapse; /* Remove any extra space between borders */
    }
    .nutpie th, .nutpie td {
        padding: 8px 10px; /* Reduce padding to make table more compact */
        text-align: left;
        border-bottom: 1px solid #888;
    }
    .nutpie th {
        //background-color: #f0f0f0;
    }

    .nutpie th:nth-child(1) { width: var(--column-width-1); }
    .nutpie th:nth-child(2) { width: var(--column-width-2); }
    .nutpie th:nth-child(3) { width: var(--column-width-3); }
    .nutpie th:nth-child(4) { width: var(--column-width-4); }
    .nutpie th:nth-child(5) { width: var(--column-width-5); }

    .nutpie progress {
        width: 100%;
        height: 15px; /* Smaller progress bars */
        border-radius: 5px;
    }
    progress::-webkit-progress-bar {
        background-color: #eee;
        border-radius: 5px;
    }
    progress::-webkit-progress-value {
        background-color: #5cb85c;
        border-radius: 5px;
    }
    progress::-moz-progress-bar {
        background-color: #5cb85c;
        border-radius: 5px;
    }
    .nutpie .progress-cell {
        width: 100%;
    }

    .nutpie p strong { font-size: 16px; font-weight: bold; }

    @media (prefers-color-scheme: dark) {
        .nutpie {
            //color: #ddd;
            //background-color: #1e1e1e;
            box-shadow: 0 4px 6px rgba(0,0,0,0.2);
        }
        .nutpie table, .nutpie th, .nutpie td {
            border-color: #555;
            color: #ccc;
        }
        .nutpie th {
            background-color: #2a2a2a;
        }
        .nutpie progress::-webkit-progress-bar {
            background-color: #444;
        }
        .nutpie progress::-webkit-progress-value {
            background-color: #3178c6;
        }
        .nutpie progress::-moz-progress-bar {
            background-color: #3178c6;
        }
    }
</style>
</div>
<div class="cell-output cell-output-display">

<div class="nutpie">
    <p><strong>Sampler Progress</strong></p>
    <p>Total Chains: <span id="total-chains">6</span></p>
    <p>Active Chains: <span id="active-chains">0</span></p>
    <p>
        Finished Chains:
        <span id="active-chains">6</span>
    </p>
    <p>Sampling for 15 seconds</p>
    <p>
        Estimated Time to Completion:
        <span id="eta">now</span>
    </p>

    <progress id="total-progress-bar" max="7800" value="7800">
    </progress>
    <table>
        <thead>
            <tr>
                <th>Progress</th>
                <th>Draws</th>
                <th>Divergences</th>
                <th>Step Size</th>
                <th>Gradients/Draw</th>
            </tr>
        </thead>
        <tbody id="chain-details">
            
                <tr>
                    <td class="progress-cell">
                        <progress max="1300" value="1300">
                        </progress>
                    </td>
                    <td>1300</td>
                    <td>44</td>
                    <td>0.08</td>
                    <td>63</td>
                </tr>
            
                <tr>
                    <td class="progress-cell">
                        <progress max="1300" value="1300">
                        </progress>
                    </td>
                    <td>1300</td>
                    <td>42</td>
                    <td>0.07</td>
                    <td>63</td>
                </tr>
            
                <tr>
                    <td class="progress-cell">
                        <progress max="1300" value="1300">
                        </progress>
                    </td>
                    <td>1300</td>
                    <td>89</td>
                    <td>0.10</td>
                    <td>63</td>
                </tr>
            
                <tr>
                    <td class="progress-cell">
                        <progress max="1300" value="1300">
                        </progress>
                    </td>
                    <td>1300</td>
                    <td>452</td>
                    <td>0.11</td>
                    <td>3</td>
                </tr>
            
                <tr>
                    <td class="progress-cell">
                        <progress max="1300" value="1300">
                        </progress>
                    </td>
                    <td>1300</td>
                    <td>125</td>
                    <td>0.12</td>
                    <td>31</td>
                </tr>
            
                <tr>
                    <td class="progress-cell">
                        <progress max="1300" value="1300">
                        </progress>
                    </td>
                    <td>1300</td>
                    <td>385</td>
                    <td>0.12</td>
                    <td>31</td>
                </tr>
            
            
        </tbody>
    </table>
</div>
</div>
</div>
<div id="cf8ebfa1-6947-4301-bf11-4a5283a5bc3f" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>idata <span class="op">=</span> sampler.wait() <span class="co"># block from making changes to the notebook and wait till them sampler is finished, when its done return the idata object</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="fae68df1-371d-401a-9bfa-a7ec6330c827" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>var_names <span class="op">=</span> [</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"eta"</span>,</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"ell"</span>,</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"sigma"</span>,</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"intercept"</span>,</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>az.summary(idata, var_names<span class="op">=</span>var_names)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">sd</th>
<th data-quarto-table-cell-role="th">hdi_3%</th>
<th data-quarto-table-cell-role="th">hdi_97%</th>
<th data-quarto-table-cell-role="th">mcse_mean</th>
<th data-quarto-table-cell-role="th">mcse_sd</th>
<th data-quarto-table-cell-role="th">ess_bulk</th>
<th data-quarto-table-cell-role="th">ess_tail</th>
<th data-quarto-table-cell-role="th">r_hat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">eta</td>
<td>0.690</td>
<td>0.276</td>
<td>0.289</td>
<td>1.287</td>
<td>0.051</td>
<td>0.041</td>
<td>45.0</td>
<td>45.0</td>
<td>1.12</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">ell</td>
<td>95.670</td>
<td>29.419</td>
<td>46.995</td>
<td>142.744</td>
<td>4.286</td>
<td>3.050</td>
<td>50.0</td>
<td>561.0</td>
<td>1.09</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">sigma</td>
<td>0.094</td>
<td>0.007</td>
<td>0.080</td>
<td>0.108</td>
<td>0.001</td>
<td>0.001</td>
<td>47.0</td>
<td>37.0</td>
<td>1.08</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">intercept</td>
<td>-0.074</td>
<td>0.535</td>
<td>-0.914</td>
<td>0.992</td>
<td>0.129</td>
<td>0.093</td>
<td>19.0</td>
<td>16.0</td>
<td>1.26</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="dd7a0ab8-fb1b-4b6c-a959-f22606dce0ab" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>az.plot_trace(idata, var_names<span class="op">=</span>var_names)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-22-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="8e68f33f-dbce-423d-962a-6ed9e16e5c40" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">4</span>))</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> az.extract(idata, var_names<span class="op">=</span><span class="st">"mu"</span>).data.T</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>pm.gp.util.plot_gp_dist(ax<span class="op">=</span>axs[<span class="dv">0</span>], samples<span class="op">=</span>mu, x<span class="op">=</span>x)<span class="op">;</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> az.extract(idata, var_names<span class="op">=</span><span class="st">"f"</span>).data.T</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>pm.gp.util.plot_gp_dist(ax<span class="op">=</span>axs[<span class="dv">1</span>], samples<span class="op">=</span>f, x<span class="op">=</span>x)<span class="op">;</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> axs[:<span class="dv">2</span>]:</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>    ax.plot(x, f_true)<span class="op">;</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>    ax.scatter(x, y, color<span class="op">=</span><span class="st">"c"</span>)<span class="op">;</span></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>    ax.set_ylim([<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>])<span class="op">;</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>    ax.set_xlim([<span class="dv">0</span>, <span class="bu">max</span>(x)])<span class="op">;</span></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>az.plot_dist(idata.posterior.intercept, ax<span class="op">=</span>axs[<span class="dv">2</span>])<span class="op">;</span></span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_title(<span class="st">"posterior of intercept + f"</span>)<span class="op">;</span></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_title(<span class="st">"posterior of f only"</span>)<span class="op">;</span></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">2</span>].set_title(<span class="st">"posterior of intercept only"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-23-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="results" class="level3">
<h3 class="anchored" data-anchor-id="results">Results</h3>
<p>There are a couple observations we can make:</p>
<ol type="1">
<li>There are <em>a lot</em> of divergences. One or two aren’t a big deal <font color="blue">, especially when dealing with GPs</font>, but a few hundred is. Looking at the plot of <code>posterior of intercept + f</code>, in the left in the plot above, we can see that the data strongly informs the GP. That is, if we <em>should</em> be able to get a nice fit there, because we have a lot of data and relatively little noise. This information tells us to try switching to the <code>parameterization="centered"</code>. The default for HSGP is <code>parameterization="noncentered"</code>. When the GP is strongly informed by the data (think, low noise, easy to detect) the <code>centered</code> parameterization performs better. When the GP is buried under noise or weakly informed by the data, (think time varying parameters in MMMs, noisy data) then <code>noncentered</code> is usually the best). The divergences mean <a href="https://crackedbassoon.com/writing/funneling">there’s a funnel somewhere, more information here</a>.</li>
<li>While the fit, <code>intercept + mu</code> is well informed and has a narrow posterior, the posteriors of <code>f</code> and the <code>intercept</code> are both very wide. This suggests that there is <em>a lot</em> of correlation in their posterior distributions. When the <code>intercept</code> is small, then <code>f</code> is large; and when the <code>intercept</code> is large, then <code>f</code> is small, always cancelling each other out. This tells us that the GP and the intercept have an identifiability issue. We can solve this either by placing a much stronger prior on the intercept (which is like adding a lot of information), or just taking that parameter out entirely.</li>
</ol>
<p>Next, we’ll switch the parameterization and remove the intercept to see if that solves the problem.</p>
</section>
<section id="aside-centered-vs.-non-centered-parameterizations" class="level3">
<h3 class="anchored" data-anchor-id="aside-centered-vs.-non-centered-parameterizations">Aside: centered vs.&nbsp;non-centered parameterizations</h3>
<p>Both parameterizations have the same number of unknown parameters, and on paper, they are mathematically equivalent. Which parameterization works better in practice (honestly, very annoyingly) depends on the geometery of the posterior distribution, how “funnely” it is. This means you have to start sampling to figure out which parameterization to use, so be ready to code it up both ways. Unfortunately no one has come up with a nice way to do this automatically in PyMC (or Stan or any other PPL). The rule of thumb is that when the posterior is strongly informed by the data, the centered parameterization works better. When the posterior is weakly informed by the data, the non-centered parameterization works better. This is a really rough argument, but I’ll try to make it for intuitions sake. Written out, the two parameterizations are:</p>
<ol type="1">
<li>Centered: <span class="math inline">\(x \sim N(\mu, \sigma)\)</span>.</li>
<li>Non-centered <span class="math inline">\(z \sim N(0, 1)\)</span>, <span class="math inline">\(x = \mu + z \sigma\)</span>.</li>
</ol>
<p>In the centered parameterization, you’re inferring <span class="math inline">\(x\)</span> directly. If you have a sharp posterior on <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>, it’s going to be easier to get the posterior of <span class="math inline">\(x\)</span>. In the non-centered parameterization, you’re instead inferring <span class="math inline">\(z\)</span> and then scaling it and shifting it. The sampler has an easier time doing this when there’s more uncertainty about <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>.</p>
<p>Below is a super simple demo. The centered vs non-centered parameterization is commented in the model code. You could think of the following scenario: - Each observed data point is a student’s test score - Each group is a classroom within a school.</p>
<p>A hierarchical model applies here because you don’t necessarily assume that each student is completely independent of the others. Since they all go to the same school, they all likely have somewhat similar socioeconomic backgrounds. This is reflected in the way the data is generated. That means there’s an global average test score across all students, and then there is a group level average test score. The value of <code>sigma</code> gives the student level variance, and the value of <code>sigma_group</code> gives the variance between he means of the groups.</p>
<p>In this example, notice that the group means are easy to detect, because <code>sigma_group_true = 5</code>. You’ll get a lot of divergences. Try changing to the centered parameterization. Also experiment with different values of <code>delta_group_true</code>, <code>sigma_true</code> and <code>n_groups</code>. Also remember to check the priors that are being set on these parameters.</p>
<div id="6c6b1473-ad23-45f3-9f3b-b94e6c9885eb" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># simulate data from the generative process of a simple normal hierarchical model</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>n_data <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>n_groups <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>mu_true <span class="op">=</span> <span class="fl">1.5</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>sigma_group_true <span class="op">=</span> <span class="fl">5.0</span> <span class="co"># centered is best</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co">#sigma_group_true = 0.1 # non-centered is best</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>delta_group_true <span class="op">=</span> sigma_group_true <span class="op">*</span> rng.normal(size<span class="op">=</span>n_groups)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>sigma_true <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>ix <span class="op">=</span> rng.choice(np.arange(n_groups), size<span class="op">=</span>n_data)</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>y_obs <span class="op">=</span> mu_true <span class="op">+</span> delta_group_true[ix] <span class="op">+</span> sigma_true <span class="op">*</span> rng.normal(size<span class="op">=</span>n_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="053ad1b3-6dcb-418f-8c5d-a21e0ad0ea97" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the generated data</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>add_jitter <span class="op">=</span> <span class="kw">lambda</span> x, eps: x <span class="op">+</span> eps <span class="op">*</span> np.random.randn(<span class="bu">len</span>(x))</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>group_labels <span class="op">=</span> [<span class="st">"group </span><span class="sc">%i</span><span class="st">"</span> <span class="op">%</span> i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_groups <span class="op">+</span> <span class="dv">1</span>)]</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> np.asarray([<span class="st">"C</span><span class="sc">%s</span><span class="st">"</span> <span class="op">%</span> i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_groups)])</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>ax.scatter(</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    add_jitter(ix, <span class="fl">5e-2</span>), </span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>    y_obs,</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>    color<span class="op">=</span>colors[ix],</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">"observed data"</span>,</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>)<span class="op">;</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>ax.scatter(</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>    np.arange(n_groups),</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>    mu_true <span class="op">+</span> delta_group_true,</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>    marker<span class="op">=</span><span class="st">"_"</span>,</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>    color<span class="op">=</span><span class="st">"k"</span>,</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>    s<span class="op">=</span><span class="dv">400</span>,</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">"group means"</span>,</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>ax.axhline(y<span class="op">=</span>mu_true, color<span class="op">=</span><span class="st">"k"</span>, lw<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, linestyle<span class="op">=</span><span class="st">"--"</span>)<span class="op">;</span></span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>ax.text(<span class="fl">2.25</span>, mu_true <span class="op">+</span> <span class="fl">0.05</span>, <span class="st">"intercept"</span>)<span class="op">;</span></span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>ax.set_xticks(np.arange(n_groups), group_labels)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-25-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cf0524fd-7613-452c-89eb-012c3a0a78f0" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># PyMC model comparing centered vs. non-centered for a normal hierarchical model</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>coords <span class="op">=</span> {</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"group"</span>: group_labels,</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model(coords<span class="op">=</span>coords) <span class="im">as</span> model:</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## Prior for the mean or intercept</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> pm.Normal(<span class="st">"mu"</span>, sigma<span class="op">=</span><span class="fl">5.0</span>)</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## PC prior for the variance of a normal random effect</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>    alpha, U <span class="op">=</span> <span class="fl">0.1</span>, <span class="fl">1.0</span>  <span class="co"># set tail probability, p(sigma_group &gt; U) = alpha</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>    sigma_group <span class="op">=</span> pm.Exponential(<span class="st">"sigma_group"</span>, lam<span class="op">=-</span>np.log(alpha) <span class="op">/</span> U)</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">## Centered parameterization</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">#group_effect = pm.Normal("group_effect", mu=mu, sigma=sigma_group, dims="group")</span></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">## Non-centered parameterization</span></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>    delta_group_z <span class="op">=</span> pm.Normal(<span class="st">"delta_group_z"</span>, dims<span class="op">=</span><span class="st">"group"</span>)</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>    group_effect <span class="op">=</span> pm.Deterministic(<span class="st">"group_effect"</span>, mu <span class="op">+</span> sigma_group <span class="op">*</span> delta_group_z, dims<span class="op">=</span><span class="st">"group"</span>)</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>    <span class="co">## likelihood</span></span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> pm.HalfNormal(<span class="st">"sigma"</span>, sigma<span class="op">=</span><span class="fl">5.0</span>)</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>    pm.Normal(<span class="st">"y"</span>, mu<span class="op">=</span>group_effect[ix], sigma<span class="op">=</span>sigma, observed<span class="op">=</span>y_obs)</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>    idata <span class="op">=</span> pm.sample()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [mu, sigma_group, delta_group_z, sigma]
/home/bill/miniforge3/envs/techstyle/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"61f58e1f086a40629643294dc0a9ae7a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/bill/miniforge3/envs/techstyle/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 5 seconds.
There were 1 divergences after tuning. Increase `target_accept` or reparameterize.</code></pre>
</div>
</div>
<p>In Gaussian processes, the centered vs.&nbsp;non-centered parameterization is on <em>multivariate</em> normals, instead of univariate normals. The different representations are: 1. Centered: <span class="math inline">\(\mathbf{x} \sim \text{MvN}(0, \mathbf{K})\)</span> 2. Non-centered: <span class="math inline">\(K = L L^T\)</span>, <span class="math inline">\(\mathbf{z} \sim \text{MvN}(\mu, I)\)</span>, <span class="math inline">\(\mathbf{x} = \mu + L \mathbf{z}\)</span>.</p>
<p><span class="math inline">\(\mathbf{x}\)</span> is the sample from the multivariate normal, <span class="math inline">\(K\)</span> is the covariance matrix. <span class="math inline">\(L\)</span> is the “square root” of the covariance matrix, called the Cholesky factor. Finally, <span class="math inline">\(z\)</span> is a sample.</p>
</section>
<section id="back-to-gps" class="level3">
<h3 class="anchored" data-anchor-id="back-to-gps">Back to GPs</h3>
<p>Here’s what happens if we change the parameterization and remove the intercept.</p>
<div id="0b773895-a54f-41ed-89c7-0dff9b9adcbb" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># tail probability p(eta &gt; 1.0) = 0.1</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    alpha, U <span class="op">=</span> <span class="fl">0.1</span>, <span class="fl">10.0</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    eta <span class="op">=</span> pm.Exponential(<span class="st">"eta"</span>, lam<span class="op">=-</span>np.log(alpha) <span class="op">/</span> U)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    ell <span class="op">=</span> pm.InverseGamma(</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">"ell"</span>,</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>        <span class="op">**</span>pm.find_constrained_prior(</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>            pm.InverseGamma,</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>            lower<span class="op">=</span><span class="dv">50</span>, upper<span class="op">=</span><span class="dv">500</span>, mass<span class="op">=</span><span class="fl">0.95</span>,</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>            init_guess<span class="op">=</span>{<span class="st">"mu"</span>: <span class="fl">100.0</span>, <span class="st">"sigma"</span>: <span class="fl">50.0</span>},</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>    cov_func <span class="op">=</span> eta<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> pm.gp.cov.Matern52(input_dim<span class="op">=</span><span class="dv">1</span>, ls<span class="op">=</span>ell)</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>    gp <span class="op">=</span> pm.gp.HSGP(m<span class="op">=</span>[<span class="dv">200</span>], c<span class="op">=</span><span class="fl">10.0</span>, cov_func<span class="op">=</span>cov_func, parametrization<span class="op">=</span><span class="st">"centered"</span>)</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">#intercept = pm.Normal("intercept", mu=0.0, sigma=5.0)</span></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>    intercept <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>    f <span class="op">=</span> gp.prior(<span class="st">"f"</span>, X<span class="op">=</span>x[:, <span class="va">None</span>])</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> pm.Deterministic(<span class="st">"mu"</span>, intercept <span class="op">+</span> f)</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> pm.Exponential(<span class="st">"sigma"</span>, scale<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>    pm.Normal(<span class="st">"y"</span>, mu<span class="op">=</span>f, sigma<span class="op">=</span>sigma, observed<span class="op">=</span>y)</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>cmodel <span class="op">=</span> nutpie.compile_pymc_model(model, backend<span class="op">=</span><span class="st">"jax"</span>, gradient_backend<span class="op">=</span><span class="st">"jax"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="6fa32499-2715-45e4-94ff-b5e54fb45998" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>sampler <span class="op">=</span> nutpie.sample(</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>    compiled_model<span class="op">=</span>cmodel,</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    blocking<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    :root {
        --column-width-1: 40%; /* Progress column width */
        --column-width-2: 15%; /* Chain column width */
        --column-width-3: 15%; /* Divergences column width */
        --column-width-4: 15%; /* Step Size column width */
        --column-width-5: 15%; /* Gradients/Draw column width */
    }

    .nutpie {
        max-width: 800px;
        margin: 10px auto;
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        //color: #333;
        //background-color: #fff;
        padding: 10px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        border-radius: 8px;
        font-size: 14px; /* Smaller font size for a more compact look */
    }
    .nutpie table {
        width: 100%;
        border-collapse: collapse; /* Remove any extra space between borders */
    }
    .nutpie th, .nutpie td {
        padding: 8px 10px; /* Reduce padding to make table more compact */
        text-align: left;
        border-bottom: 1px solid #888;
    }
    .nutpie th {
        //background-color: #f0f0f0;
    }

    .nutpie th:nth-child(1) { width: var(--column-width-1); }
    .nutpie th:nth-child(2) { width: var(--column-width-2); }
    .nutpie th:nth-child(3) { width: var(--column-width-3); }
    .nutpie th:nth-child(4) { width: var(--column-width-4); }
    .nutpie th:nth-child(5) { width: var(--column-width-5); }

    .nutpie progress {
        width: 100%;
        height: 15px; /* Smaller progress bars */
        border-radius: 5px;
    }
    progress::-webkit-progress-bar {
        background-color: #eee;
        border-radius: 5px;
    }
    progress::-webkit-progress-value {
        background-color: #5cb85c;
        border-radius: 5px;
    }
    progress::-moz-progress-bar {
        background-color: #5cb85c;
        border-radius: 5px;
    }
    .nutpie .progress-cell {
        width: 100%;
    }

    .nutpie p strong { font-size: 16px; font-weight: bold; }

    @media (prefers-color-scheme: dark) {
        .nutpie {
            //color: #ddd;
            //background-color: #1e1e1e;
            box-shadow: 0 4px 6px rgba(0,0,0,0.2);
        }
        .nutpie table, .nutpie th, .nutpie td {
            border-color: #555;
            color: #ccc;
        }
        .nutpie th {
            background-color: #2a2a2a;
        }
        .nutpie progress::-webkit-progress-bar {
            background-color: #444;
        }
        .nutpie progress::-webkit-progress-value {
            background-color: #3178c6;
        }
        .nutpie progress::-moz-progress-bar {
            background-color: #3178c6;
        }
    }
</style>
</div>
<div class="cell-output cell-output-display">

<div class="nutpie">
    <p><strong>Sampler Progress</strong></p>
    <p>Total Chains: <span id="total-chains">6</span></p>
    <p>Active Chains: <span id="active-chains">0</span></p>
    <p>
        Finished Chains:
        <span id="active-chains">6</span>
    </p>
    <p>Sampling for 33 seconds</p>
    <p>
        Estimated Time to Completion:
        <span id="eta">now</span>
    </p>

    <progress id="total-progress-bar" max="7800" value="7800">
    </progress>
    <table>
        <thead>
            <tr>
                <th>Progress</th>
                <th>Draws</th>
                <th>Divergences</th>
                <th>Step Size</th>
                <th>Gradients/Draw</th>
            </tr>
        </thead>
        <tbody id="chain-details">
            
                <tr>
                    <td class="progress-cell">
                        <progress max="1300" value="1300">
                        </progress>
                    </td>
                    <td>1300</td>
                    <td>0</td>
                    <td>0.07</td>
                    <td>31</td>
                </tr>
            
                <tr>
                    <td class="progress-cell">
                        <progress max="1300" value="1300">
                        </progress>
                    </td>
                    <td>1300</td>
                    <td>0</td>
                    <td>0.06</td>
                    <td>255</td>
                </tr>
            
                <tr>
                    <td class="progress-cell">
                        <progress max="1300" value="1300">
                        </progress>
                    </td>
                    <td>1300</td>
                    <td>0</td>
                    <td>0.13</td>
                    <td>63</td>
                </tr>
            
                <tr>
                    <td class="progress-cell">
                        <progress max="1300" value="1300">
                        </progress>
                    </td>
                    <td>1300</td>
                    <td>0</td>
                    <td>0.05</td>
                    <td>47</td>
                </tr>
            
                <tr>
                    <td class="progress-cell">
                        <progress max="1300" value="1300">
                        </progress>
                    </td>
                    <td>1300</td>
                    <td>0</td>
                    <td>0.10</td>
                    <td>15</td>
                </tr>
            
                <tr>
                    <td class="progress-cell">
                        <progress max="1300" value="1300">
                        </progress>
                    </td>
                    <td>1300</td>
                    <td>0</td>
                    <td>0.06</td>
                    <td>47</td>
                </tr>
            
            
        </tbody>
    </table>
</div>
</div>
</div>
<div id="8aaf1e7e-570a-4ddb-92fb-5018e4516cbe" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>idata <span class="op">=</span> sampler.wait()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="28b08971-3e41-47ef-b4f6-74d4d89e01fb" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>var_names <span class="op">=</span> [</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"eta"</span>,</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"ell"</span>,</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"sigma"</span>,</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>az.summary(idata, var_names<span class="op">=</span>var_names)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">sd</th>
<th data-quarto-table-cell-role="th">hdi_3%</th>
<th data-quarto-table-cell-role="th">hdi_97%</th>
<th data-quarto-table-cell-role="th">mcse_mean</th>
<th data-quarto-table-cell-role="th">mcse_sd</th>
<th data-quarto-table-cell-role="th">ess_bulk</th>
<th data-quarto-table-cell-role="th">ess_tail</th>
<th data-quarto-table-cell-role="th">r_hat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">eta</td>
<td>0.783</td>
<td>0.576</td>
<td>0.166</td>
<td>1.750</td>
<td>0.043</td>
<td>0.031</td>
<td>94.0</td>
<td>333.0</td>
<td>1.06</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">ell</td>
<td>90.749</td>
<td>32.601</td>
<td>41.341</td>
<td>149.226</td>
<td>6.523</td>
<td>4.667</td>
<td>24.0</td>
<td>115.0</td>
<td>1.18</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">sigma</td>
<td>0.093</td>
<td>0.007</td>
<td>0.081</td>
<td>0.106</td>
<td>0.000</td>
<td>0.000</td>
<td>1797.0</td>
<td>2095.0</td>
<td>1.00</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="426a27e3-3a55-4448-badb-00f65670a7f1" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>az.plot_trace(idata, var_names<span class="op">=</span>var_names)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-34-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="b173235f-747e-4dce-861f-df746cb3b2e7" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> az.extract(idata, var_names<span class="op">=</span><span class="st">"f"</span>).data.T</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>pm.gp.util.plot_gp_dist(ax<span class="op">=</span>ax, samples<span class="op">=</span>f, x<span class="op">=</span>x)<span class="op">;</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>ax.plot(x, f_true)<span class="op">;</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>ax.scatter(x, y, color<span class="op">=</span><span class="st">"c"</span>)<span class="op">;</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>ax.set_ylim([<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">1.0</span>])<span class="op">;</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>ax.set_xlim([<span class="dv">0</span>, np.<span class="bu">max</span>(x)])</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"posterior of f"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-35-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>It’s not perfect but it’s much better. There’s no intercept so we know the identifiability issue is gone. We’re still getting warnings about <code>r_hat</code> though. Since the function changes so slowly, the model is unable to learn much about the lengthscale, only that it’s large. With data like this, a GP is probably overkill. We might be better off just using a simple linear trend to model something like this, but that depends on the context. Below we’ll plot the posterior vs.&nbsp;the prior on the lengthscale.</p>
<div id="9d4a0b02-1e4d-4197-a6ba-e84231db9e4e" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>ell <span class="op">=</span> az.extract(idata, var_names<span class="op">=</span><span class="st">"ell"</span>).data</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>bins <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">350</span>, <span class="dv">100</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>plt.hist(ell, density<span class="op">=</span><span class="va">True</span>, bins<span class="op">=</span>bins, label<span class="op">=</span><span class="st">"posterior"</span>)<span class="op">;</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>ell_prior <span class="op">=</span> pm.InverseGamma.dist(</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>    <span class="op">**</span>pm.find_constrained_prior(</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>        pm.InverseGamma,</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>        lower<span class="op">=</span><span class="fl">50.0</span>, upper<span class="op">=</span><span class="fl">500.0</span>, mass<span class="op">=</span><span class="fl">0.95</span>,</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>        init_guess<span class="op">=</span>{<span class="st">"mu"</span>: <span class="fl">100.0</span>, <span class="st">"sigma"</span>: <span class="fl">50.0</span>},</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> pm.draw(ell_prior, <span class="dv">6000</span>)</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>plt.hist(s, density<span class="op">=</span><span class="va">True</span>, bins<span class="op">=</span>bins, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">"prior"</span>, color<span class="op">=</span><span class="st">"k"</span>)<span class="op">;</span></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>plt.yticks([])<span class="op">;</span></span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Lengthscale prior and posterior"</span>)<span class="op">;</span></span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>plt.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-36-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>You can see that we didn’t learn too much about the lengthscale from the data. This is a pretty common pattern with GPs, the data doesn’t inform the lengthscale well. This isn’t necessarily bad though – what’s really happeneing is we’re averaging over many possible models with varying complexity, just using a single lengthscale parameter. For more info on lengthscales, take a look at <a href="https://drive.google.com/file/d/0B3WHb3BabixAYlptTVBWUGdyVEE/view?resourcekey=0-mj7f4AZQ-UN1Rvd9NrRlHg">this short tech note</a>.</p>
<p>You could also consider fixing the lengthscale to a large value, far above the range of the data. I’d put a heavy asterisk on the results of a model with a fixed lengthscale though, especially in the context of forecasting, because you can also understand the lengthscale as controlling how far into the future you can make forecasts. This is something you want the data to determine. We’ll see this later.</p>
<p>To summarize, the first problem was using the <code>noncentered</code> parameterization when the GP is strongly informed by the data. Then the second issue was that intercept and the GP are difficult to identify in this case. If you shifted the GP up so it was centered around say, y=100, then you would want to keep the intercept!</p>
</section>
</section>
<section id="example-2-a-more-common-example" class="level2">
<h2 class="anchored" data-anchor-id="example-2-a-more-common-example">Example 2: A more common example</h2>
<p>This problem was difficult, and we had to dig into the bag of tricks a bit to get it to fit reasonably well. Now let’s see what happens on a less unusual problem. Below is a squared sin wave that’s oscillating on a monthly time scale. It represents the average number of sales per day. The observed data is a sales count, so we’ll model this as a Poisson process. This may be more like problems you’ll encounter in practice. We have some zero crossings so we’ll be able to say something more concrete about the best lengthscale.</p>
<p>The Poisson distribution is a simple distribution that over integer values, 0, 1, 2, 3, etc. It’s often used for count data. It’s even simpler than the normal because it’s controlled by one parameter (<code>mu</code>) instead of two for the normal, <code>mu</code> and <code>sigma</code>. This is why I chose it for the example. In a Poisson distribution, <code>mu</code> is both the mean and the variance, and it often makes sense that as the mean increases the variance also increases.</p>
<p>You need to exponentiate the linear predictor (you’d say you’re using the log link function) because the mean of a Poisson is restricted to be positive.</p>
<p><strong>I had to restart the kernel, and not use the nutpie sampler to get the prediction examples to work</strong>. I’m sure this’ll get fixed soon.</p>
<div id="812da6b5-db2e-401f-8cd9-5964851bb3f8" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pytensor.tensor <span class="im">as</span> pt</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nutpie</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>RANDOM_SEED <span class="op">=</span> <span class="dv">8998</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(RANDOM_SEED)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="d89a7cf1-0240-4b07-ae4f-742f8479d4c2" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(<span class="dv">70</span>)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>f_true <span class="op">=</span> np.exp(<span class="fl">2.0</span> <span class="op">*</span> np.sin(<span class="dv">2</span> <span class="op">*</span> np.pi <span class="op">*</span> x <span class="op">*</span> (<span class="dv">1</span> <span class="op">/</span> <span class="dv">30</span>)))</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> rng.poisson(lam<span class="op">=</span>f_true)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>plt.plot(x, f_true)<span class="op">;</span></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>plt.scatter(x, y, color<span class="op">=</span><span class="st">"c"</span>)<span class="op">;</span></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"day"</span>)<span class="op">;</span></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"number of sales"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-38-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Again I’ll lay out my thought process for setting priors. You’ll notice most of it is the same as before, exponential prior on <code>eta</code>, inverse gamma on <code>ell</code>. This time though the likelihood is Poisson so we don’t have a <code>sigma</code> parameter to worry about, but we do need to exponentiate the GP to keep it positive valued.</p>
<ol type="1">
<li>I’ll set <code>eta</code> first. The data ranges from around 0 to 12. The log of 12 is about 2.5, so <code>eta</code> is going to be somewhere around there. I’m going to say that there’s a 10% chance <code>eta</code> is larger than 5.0 to be conservative.</li>
<li>We know the process repeats every 30 days. But, one thing about lengthscales I haven’t mentioned is that <strong>they need to be small enough to handle the most wiggly significant part of the curve</strong>. A short lengthscale can follow along a slowly changing curve, but a long lengthcale GP can’t bend enough to hit a quick variation. Those peaks are pretty sharp, so I’ll say that the lengthscale should be between 5 and 35 with a 95% probability.</li>
<li>Since we’re using the HSGP again, I’ll use the function <code>pm.gp.hsgp_approx.approx_hsgp_hyperparams</code> to set help me choose <code>m</code> and <code>c</code>.</li>
</ol>
<div id="595abe0a-ed64-4837-a936-846ca4e94fd9" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co">## calculate minimum recommended m and c values (larger is ok, but less efficient)</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>m, c <span class="op">=</span> pm.gp.hsgp_approx.approx_hsgp_hyperparams(x_range<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">200</span>], lengthscale_range<span class="op">=</span>[<span class="dv">3</span>, <span class="dv">20</span>], cov_func<span class="op">=</span><span class="st">"matern52"</span>)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>m, c</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>(106, 1.2)</code></pre>
</div>
</div>
<div id="485ae9af-736f-434c-b01e-ef1b971ef368" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>    alpha, U <span class="op">=</span> <span class="fl">0.1</span>, <span class="fl">5.0</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>    eta <span class="op">=</span> pm.Exponential(<span class="st">"eta"</span>, lam<span class="op">=-</span>np.log(alpha) <span class="op">/</span> U)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>    ell <span class="op">=</span> pm.InverseGamma(</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">"ell"</span>,</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>        <span class="op">**</span>pm.find_constrained_prior(</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>            pm.InverseGamma,</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>            lower<span class="op">=</span><span class="fl">3.0</span>, upper<span class="op">=</span><span class="fl">20.0</span>, mass<span class="op">=</span><span class="fl">0.95</span>,</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>            init_guess<span class="op">=</span>{<span class="st">"mu"</span>: <span class="fl">10.0</span>, <span class="st">"sigma"</span>: <span class="fl">5.0</span>},</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>    cov_func <span class="op">=</span> eta<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> pm.gp.cov.Matern52(input_dim<span class="op">=</span><span class="dv">1</span>, ls<span class="op">=</span>ell)</span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>    gp <span class="op">=</span> pm.gp.HSGP(m<span class="op">=</span>[<span class="dv">200</span>], c<span class="op">=</span><span class="fl">3.0</span>, cov_func<span class="op">=</span>cov_func, parametrization<span class="op">=</span><span class="st">"centered"</span>)</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> pm.Data(<span class="st">"X"</span>, x[:, <span class="va">None</span>])</span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>    phi, sqrt_psd <span class="op">=</span> gp.prior_linearized(X<span class="op">=</span>X)</span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>    basis_coeffs <span class="op">=</span> pm.Normal(<span class="st">"basis_coeffs"</span>, size<span class="op">=</span>gp.n_basis_vectors)</span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>    f <span class="op">=</span> pm.Deterministic(<span class="st">"f"</span>, phi <span class="op">@</span> (basis_coeffs <span class="op">*</span> sqrt_psd))</span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a>    log_mu <span class="op">=</span> pm.Deterministic(<span class="st">"log_mu"</span>, f)</span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a>    pm.Poisson(<span class="st">"y"</span>, mu<span class="op">=</span>pt.exp(log_mu), observed<span class="op">=</span>y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We’re using an alternative way to write the GP to make it easier to make forecasts. Instead of <code>gp.prior</code>, we’re using <code>gp.prior_linearized</code>. <code>pm.gp.HSGP</code> is meant to be a drop in replacement to <code>pm.gp.Latent</code> with minimal changes to the code. However, one really big benefit of the HSGP approximation is that under the hood it’s a linear model, which means we can use <code>pm.set_data</code> instead of having to write custom GP specific code for predictions. Compare <a href="https://www.pymc.io/projects/examples/en/latest/gaussian_processes/GP-Latent.html#prediction-using-conditional">how you make predictions for <code>pm.gp.Latent</code> here</a> vs.&nbsp;<a href="https://www.pymc.io/projects/examples/en/latest/gaussian_processes/HSGP-Basic.html#example-2-working-with-hsgps-as-a-parametric-linear-model">how you make predictions for <code>pm.gp.HSGP</code> here</a>.</p>
<div id="2e81b1b1-0908-4cd4-814c-fc76332d9c0d" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> model:</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>    idata <span class="op">=</span> pm.sample(nuts_sampler<span class="op">=</span><span class="st">"numpyro"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c5dbe5f0e46d47dd94c17bd58d2250f0","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"285f35a383f74f208725a1da763233ea","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9c9189e7c635430fa8bfbc36dc786445","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ea344ed4116940c680e43317fcfe8dc7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>There were 6 divergences after tuning. Increase `target_accept` or reparameterize.</code></pre>
</div>
</div>
<div id="45aaf1b5-7e19-4bf7-8d27-ca49580e9bdb" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>var_names <span class="op">=</span> [</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"eta"</span>,</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"ell"</span>,</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>az.summary(idata, var_names<span class="op">=</span>var_names)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="46">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">sd</th>
<th data-quarto-table-cell-role="th">hdi_3%</th>
<th data-quarto-table-cell-role="th">hdi_97%</th>
<th data-quarto-table-cell-role="th">mcse_mean</th>
<th data-quarto-table-cell-role="th">mcse_sd</th>
<th data-quarto-table-cell-role="th">ess_bulk</th>
<th data-quarto-table-cell-role="th">ess_tail</th>
<th data-quarto-table-cell-role="th">r_hat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">eta</td>
<td>2.090</td>
<td>0.703</td>
<td>1.008</td>
<td>3.382</td>
<td>0.022</td>
<td>0.016</td>
<td>1172.0</td>
<td>1197.0</td>
<td>1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">ell</td>
<td>8.828</td>
<td>2.186</td>
<td>5.000</td>
<td>12.827</td>
<td>0.060</td>
<td>0.044</td>
<td>1465.0</td>
<td>1469.0</td>
<td>1.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="c904c7b9-c763-44c9-92a2-a974846a5ae2" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>az.plot_trace(idata, var_names<span class="op">=</span>var_names)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-43-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="e18e3ba2-5da5-431a-b4fb-76998ea4f5c7" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> az.extract(idata, var_names<span class="op">=</span><span class="st">"f"</span>).data.T</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>pm.gp.util.plot_gp_dist(ax<span class="op">=</span>ax, samples<span class="op">=</span>np.exp(f), x<span class="op">=</span>x)<span class="op">;</span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>ax.plot(x, f_true)<span class="op">;</span></span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>ax.scatter(x, y, color<span class="op">=</span><span class="st">"c"</span>)<span class="op">;</span></span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>ax.set_xlim([<span class="dv">0</span>, np.<span class="bu">max</span>(x)])</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"posterior of f"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-44-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>There were a few divergences. I tried it with <code>parametrization=non-centered</code> and that didn’t really help, so I think it’s safe to increase the <code>target_accept</code> of the sampler and try again. The reason you don’t just start by setting <code>target_accept=0.999</code> and forget about it is that it’ll both slow down sampling and potentially paper over issues with your model that could be more robustly fixed by reparameterization of searching for identifiability issues. Also, if there are serious identifiability / funnel issues, it’s unlikely that increasing <code>target_accept</code> will be enough to fix sampling.</p>
<div id="c0660b68-47a9-4dfe-b9dc-53d52d788d1e" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> model:</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>    idata <span class="op">=</span> pm.sample(nuts_sampler<span class="op">=</span><span class="st">"numpyro"</span>, target_accept<span class="op">=</span><span class="fl">0.95</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4fae13d2baa548c39be9904210fd5204","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e43522e0ab48475e9b48bdf079706cdb","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d910a3885a9b44959d25fe92d7fddbd0","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5a55f3bf496a4cdcbffb5011552ff475","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details</code></pre>
</div>
</div>
<div id="0e369928-3b89-4cf7-8a94-6d99a1b73b51" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>var_names <span class="op">=</span> [</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"eta"</span>,</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"ell"</span>,</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>az.summary(idata, var_names<span class="op">=</span>var_names)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">sd</th>
<th data-quarto-table-cell-role="th">hdi_3%</th>
<th data-quarto-table-cell-role="th">hdi_97%</th>
<th data-quarto-table-cell-role="th">mcse_mean</th>
<th data-quarto-table-cell-role="th">mcse_sd</th>
<th data-quarto-table-cell-role="th">ess_bulk</th>
<th data-quarto-table-cell-role="th">ess_tail</th>
<th data-quarto-table-cell-role="th">r_hat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">eta</td>
<td>2.077</td>
<td>0.726</td>
<td>0.999</td>
<td>3.396</td>
<td>0.016</td>
<td>0.011</td>
<td>2054.0</td>
<td>2626.0</td>
<td>1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">ell</td>
<td>8.757</td>
<td>2.151</td>
<td>4.852</td>
<td>12.623</td>
<td>0.039</td>
<td>0.029</td>
<td>3212.0</td>
<td>3229.0</td>
<td>1.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="62d03048-df95-45f5-96fb-069b0021a723" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>az.plot_trace(idata, var_names<span class="op">=</span>var_names)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-47-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="prediction-with-hsgps" class="level1">
<h1>Prediction with HSGPs</h1>
<p>Mechanically, information on HSGP prediction is <a href="https://www.pymc.io/projects/examples/en/latest/gaussian_processes/HSGP-Basic.html#out-of-sample-predictions">covered in detail here</a>. There are a couple important things to remember: - Gaussian processes with <code>Matern</code> or <code>ExpQuad</code> revert to the prior you chose when you forecast some distance past the lengthscale (which you infer from the data). - The uncertainty in the forecast depends on the lengthscale and the scale <code>eta</code>. - For HSGPs, some care needs to be taken when setting <code>c</code>. <code>c</code> is the “radius” of the approximation. For example, if your <span class="math inline">\(x\)</span> data is between 0 and 10, setting c=2 will set the boundary of the approximation at twice the original domain. Long story short, set <code>c</code> large enough so that edge effects don’t mess up your forecasts. Once we look, the effect is pretty obvious.</p>
<p>The original data went to 70 days. Let’s start by forecasting out to 100 days, which is as easy as replacing the <code>x</code> in our moidel with <code>x_new</code> and then drawing posterior predictive samples.</p>
<div id="4c9336be-fd55-4eb2-b631-3be59f8a5a3a" class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>x_new <span class="op">=</span> np.arange(<span class="dv">100</span>)</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> model:</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>    pm.set_data({<span class="st">"X"</span>: x_new[:, <span class="va">None</span>]})</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>    idata.extend(pm.sample_posterior_predictive(idata, var_names<span class="op">=</span>[<span class="st">"log_mu"</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling: []</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"580ffea17585450bad36804487b2c04f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
</div>
<div id="574e1710-da36-4c67-86e1-f65fb054d2c8" class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>log_mu <span class="op">=</span> az.extract(idata.posterior_predictive, var_names<span class="op">=</span><span class="st">"log_mu"</span>).T</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>pm.gp.util.plot_gp_dist(ax<span class="op">=</span>ax, samples<span class="op">=</span>np.exp(log_mu), x<span class="op">=</span>x_new)<span class="op">;</span></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>ax.plot(x, f_true)<span class="op">;</span></span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>ax.scatter(x, y, color<span class="op">=</span><span class="st">"c"</span>)<span class="op">;</span></span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>ax.set_xlim([<span class="dv">0</span>, np.<span class="bu">max</span>(x_new)])</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>ax.set_ylim([<span class="dv">0</span>, <span class="dv">20</span>])<span class="op">;</span></span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"posterior of f"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-49-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The posterior of the lengthscale was mostly between 6 and 10, and we can see that between 6 and 10 days after day 70 the GP has nearly reverted completely to its prior. In a sense, because the GP isn’t aware of periodic behavior, it makes fairly “dumb” predictions on its own. It will continue an existing trend forward as it gradually reverts back to the prior – how gradually depends on the training data via lengthscale posterior. This makes sense because our covariance function, the Matern52, tells us that points nearby are the most correlated, and then that correlation decays with distance, which is exactly what the forecast is doing.</p>
<p>In the above example, the data has already nudged the trend back down which makes the forecast look pretty good. Let’s adjust the data by only keeping the first 64| days and trying again.</p>
<section id="example-3-a-little-less-data" class="level2">
<h2 class="anchored" data-anchor-id="example-3-a-little-less-data">Example 3: a little less data</h2>
<div id="85c4efb0-4a6b-47fb-acff-1c5d204665c7" class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(<span class="dv">64</span>)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>period <span class="op">=</span> <span class="dv">30</span></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>f_true <span class="op">=</span> np.exp(<span class="fl">2.0</span> <span class="op">*</span> np.sin(<span class="dv">2</span> <span class="op">*</span> np.pi <span class="op">*</span> x <span class="op">*</span> (<span class="dv">1</span> <span class="op">/</span> period)))</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> rng.poisson(lam<span class="op">=</span>f_true)</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>plt.plot(x, f_true)<span class="op">;</span></span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>plt.scatter(x, y, color<span class="op">=</span><span class="st">"c"</span>)<span class="op">;</span></span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"day"</span>)<span class="op">;</span></span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"number of sales"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-50-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="e9cbf1d8-03fe-4570-8105-5746775defbd" class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>    alpha, U <span class="op">=</span> <span class="fl">0.1</span>, <span class="fl">5.0</span></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>    eta <span class="op">=</span> pm.Exponential(<span class="st">"eta"</span>, lam<span class="op">=-</span>np.log(alpha) <span class="op">/</span> U)</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>    ell <span class="op">=</span> pm.InverseGamma(</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">"ell"</span>,</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>        <span class="op">**</span>pm.find_constrained_prior(</span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>            pm.InverseGamma,</span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>            lower<span class="op">=</span><span class="fl">3.0</span>, upper<span class="op">=</span><span class="fl">20.0</span>, mass<span class="op">=</span><span class="fl">0.95</span>,</span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a>            init_guess<span class="op">=</span>{<span class="st">"mu"</span>: <span class="fl">10.0</span>, <span class="st">"sigma"</span>: <span class="fl">5.0</span>},</span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb60-14"><a href="#cb60-14" aria-hidden="true" tabindex="-1"></a>    cov_func <span class="op">=</span> eta<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> pm.gp.cov.Matern52(input_dim<span class="op">=</span><span class="dv">1</span>, ls<span class="op">=</span>ell)</span>
<span id="cb60-15"><a href="#cb60-15" aria-hidden="true" tabindex="-1"></a>    gp <span class="op">=</span> pm.gp.HSGP(m<span class="op">=</span>[<span class="dv">200</span>], c<span class="op">=</span><span class="fl">3.0</span>, cov_func<span class="op">=</span>cov_func, parametrization<span class="op">=</span><span class="st">"centered"</span>)</span>
<span id="cb60-16"><a href="#cb60-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-17"><a href="#cb60-17" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> pm.Data(<span class="st">"X"</span>, x[:, <span class="va">None</span>])</span>
<span id="cb60-18"><a href="#cb60-18" aria-hidden="true" tabindex="-1"></a>    phi, sqrt_psd <span class="op">=</span> gp.prior_linearized(X<span class="op">=</span>X)</span>
<span id="cb60-19"><a href="#cb60-19" aria-hidden="true" tabindex="-1"></a>    basis_coeffs <span class="op">=</span> pm.Normal(<span class="st">"basis_coeffs"</span>, size<span class="op">=</span>gp.n_basis_vectors)</span>
<span id="cb60-20"><a href="#cb60-20" aria-hidden="true" tabindex="-1"></a>    f <span class="op">=</span> pm.Deterministic(<span class="st">"f"</span>, phi <span class="op">@</span> (basis_coeffs <span class="op">*</span> sqrt_psd))</span>
<span id="cb60-21"><a href="#cb60-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb60-22"><a href="#cb60-22" aria-hidden="true" tabindex="-1"></a>    log_mu <span class="op">=</span> pm.Deterministic(<span class="st">"log_mu"</span>, f)</span>
<span id="cb60-23"><a href="#cb60-23" aria-hidden="true" tabindex="-1"></a>    pm.Poisson(<span class="st">"y"</span>, mu<span class="op">=</span>pt.exp(log_mu), observed<span class="op">=</span>y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="97e5e5f9-f4cc-4984-9bc0-30e23e0862c3" class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> model:</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>    idata <span class="op">=</span> pm.sample(nuts_sampler<span class="op">=</span><span class="st">"numpyro"</span>, target_accept<span class="op">=</span><span class="fl">0.95</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d055d5c84ac74e0f9b2a22a0fb7b3894","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"01e74e6d265a47a3b2593b1a50dfb88c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e9d6e8a50fe6481e9183bed882221858","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cb5ab3d3ef0d41eabd6a88ac994afb64","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
<div id="c2900568-e6cb-457a-a33d-08a9dfde75a4" class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>x_new <span class="op">=</span> np.arange(<span class="dv">100</span>)</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> model:</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>    pm.set_data({<span class="st">"X"</span>: x_new[:, <span class="va">None</span>]})</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>    idata.extend(pm.sample_posterior_predictive(idata, var_names<span class="op">=</span>[<span class="st">"log_mu"</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling: []</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4e2379c2dda24449bd4cc9ca5e283ad9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
</div>
<div id="6f9ae07b-7a4b-423d-9994-704ce1582ca1" class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>log_mu <span class="op">=</span> az.extract(idata.posterior_predictive, var_names<span class="op">=</span><span class="st">"log_mu"</span>).T</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>pm.gp.util.plot_gp_dist(ax<span class="op">=</span>ax, samples<span class="op">=</span>np.exp(log_mu), x<span class="op">=</span>x_new)<span class="op">;</span></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>ax.plot(x, f_true)<span class="op">;</span></span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>ax.scatter(x, y, color<span class="op">=</span><span class="st">"c"</span>)<span class="op">;</span></span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>ax.set_xlim([<span class="dv">0</span>, np.<span class="bu">max</span>(x_new)])</span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>ax.set_ylim([<span class="dv">0</span>, <span class="dv">20</span>])<span class="op">;</span></span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"posterior of f"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-54-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This forecast looks a lot different, but it’s doing the same thing. Continuing the trend forward and then reverting to the prior after about a <code>lengthscale</code> number of days. What if we force the lengthscale to be smaller?</p>
<p>We can go into the model and fix the lengthscale parameter to a specific value with <code>pm.do</code>:</p>
<div id="0d47f5be-31f6-4e19-9588-b9067d8b3c63" class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.do(model, {<span class="st">"ell"</span>: <span class="dv">2</span>, <span class="st">"eta"</span>: <span class="fl">1.5</span>}) <span class="im">as</span> m2:</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>    idata2 <span class="op">=</span> pm.sample_posterior_predictive(idata, var_names<span class="op">=</span>[<span class="st">"log_mu"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling: []</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"68a1cf1f65b4479599a8774d96d9a8b6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
</div>
<div id="f9b76b55-c685-4a93-a0ad-3b2310aed39a" class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>log_mu <span class="op">=</span> az.extract(idata2.posterior_predictive, var_names<span class="op">=</span><span class="st">"log_mu"</span>).T</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>pm.gp.util.plot_gp_dist(ax<span class="op">=</span>ax, samples<span class="op">=</span>np.exp(log_mu), x<span class="op">=</span>x_new)<span class="op">;</span></span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>ax.plot(x, f_true)<span class="op">;</span></span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a>ax.scatter(x, y, color<span class="op">=</span><span class="st">"c"</span>)<span class="op">;</span></span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a>ax.set_xlim([<span class="dv">0</span>, np.<span class="bu">max</span>(x_new)])</span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a>ax.set_ylim([<span class="dv">0</span>, <span class="dv">20</span>])<span class="op">;</span></span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"posterior of f, lengthscale fixed at 2"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-56-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>You’ll notice that to get reasonable results you have to adjust <code>eta</code> as well – try different values. This is because for GPs, the posterior of <code>eta</code> and <code>ell</code> is <em>always</em> correlated. To get the same fit with a smaller lengthscale, you need to decrease the scale, and visa versa. Feel free to experiment with different values to get a feel for it. You’ll notice in the above plot though that the mean reversion happens extremely quickly, I’d say from <span class="math inline">\(x=64\)</span> to <span class="math inline">\(x=70\)</span>. By <span class="math inline">\(x=80\)</span> we are back at the prior. You’ll also see the effect of the lengthscale on the wigglyness of the posterior samples (faint red lines).</p>
<div id="4fc17469-1a70-49af-bcbe-75f41c11adfe" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.do(model, {<span class="st">"ell"</span>: <span class="dv">16</span>, <span class="st">"eta"</span>: <span class="fl">3.5</span>}) <span class="im">as</span> m3:</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>    idata3 <span class="op">=</span> pm.sample_posterior_predictive(idata, var_names<span class="op">=</span>[<span class="st">"log_mu"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling: []</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"603d68529a764c369d79389a65f6a1ec","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
</div>
<div id="5e5d5cf3-ab7c-44f7-b261-b3d19052e56e" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>log_mu <span class="op">=</span> az.extract(idata3.posterior_predictive, var_names<span class="op">=</span><span class="st">"log_mu"</span>).T</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>pm.gp.util.plot_gp_dist(ax<span class="op">=</span>ax, samples<span class="op">=</span>np.exp(log_mu), x<span class="op">=</span>x_new)<span class="op">;</span></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>ax.plot(x, f_true)<span class="op">;</span></span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>ax.scatter(x, y, color<span class="op">=</span><span class="st">"c"</span>)<span class="op">;</span></span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>ax.set_xlim([<span class="dv">0</span>, np.<span class="bu">max</span>(x_new)])</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>ax.set_ylim([<span class="dv">0</span>, <span class="dv">20</span>])<span class="op">;</span></span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"posterior of f, lengthscale fixed at 16"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-58-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Here the posterior samples are much smoother because of the long lengthscale, and the reversion to the mean happens much more slowly, well past <span class="math inline">\(x=80\)</span>.</p>
<p>To get “smarter” predictions from GPs, we need to find a way to either learn: 1. Longer lengthscales 2. Periodicity</p>
</section>
</section>
<section id="periodic-gps" class="level1">
<h1>Periodic GPs</h1>
<p>The best way to get longer lengthscales is to include other covariates in the model that can represent the shorter time scale variation so the GP doesn’t have to. You can also add two GPs with different lengthscales together, but be careful of identifiability issues, both on the GP and between the two lengthscale parameters. There are <a href="https://www.pymc.io/projects/examples/en/latest/gaussian_processes/GP-MeansAndCovs.html">many, many</a> covariance functions out there and they all behave differently. We’ll focus on Matern and Periodic covariance functions because those work with the very fast <code>HSGP</code> approximation.</p>
<p>For instance, here’s a plot of covariance as a function of distance for the Matern52 and the Periodic covariance functions. If you experiment with the lengthscale value in the <code>Periodic</code> covariance, you’ll notice it plays a slightly different role than it does in Matern covariances.</p>
<div id="a48a05fd-a050-4cb4-bf29-442c934547fd" class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">100</span>)</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>cov1 <span class="op">=</span> pm.gp.cov.Matern52(<span class="dv">1</span>, ls<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>cov2 <span class="op">=</span> pm.gp.cov.Periodic(<span class="dv">1</span>, period<span class="op">=</span><span class="dv">3</span>, ls<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>K1 <span class="op">=</span> cov1(x[:, <span class="va">None</span>])</span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>K2 <span class="op">=</span> cov2(x[:, <span class="va">None</span>])</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a>plt.plot(x, K1[:, <span class="dv">0</span>].<span class="bu">eval</span>(), label<span class="op">=</span><span class="st">"Matern52"</span>)</span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a>plt.plot(x, K2[:, <span class="dv">0</span>].<span class="bu">eval</span>(), label<span class="op">=</span><span class="st">"Periodic"</span>)<span class="op">;</span></span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a>plt.legend()<span class="op">;</span></span>
<span id="cb71-12"><a href="#cb71-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"covariance"</span>)<span class="op">;</span></span>
<span id="cb71-13"><a href="#cb71-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"x distance"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-59-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>For Matern kernels, as distance between x points increases, the covariance decreases. That’s not the case for periodic covariances. As distance increases, covariance oscillates. This produces functions that oscillate too. For instance, when two points <span class="math inline">\(x\)</span> and <span class="math inline">\(x'\)</span> are a distance of 3 away from eachother, the covariance equals one. This means the <span class="math inline">\(y\)</span> values have to be <em>exactly</em> the same.</p>
<p>Before fitting a model, let’s look at some samples from the prior of a GP with a periodic covariance function.</p>
<div id="76f9624b-83ab-4571-813f-398db38cf438" class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">100</span>)</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>cov <span class="op">=</span> pm.gp.cov.Periodic(<span class="dv">1</span>, period<span class="op">=</span><span class="dv">3</span>, ls<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> pm.draw(pm.MvNormal.dist(mu<span class="op">=</span>np.zeros(<span class="dv">100</span>), cov<span class="op">=</span>cov(x[:, <span class="va">None</span>])), <span class="dv">5</span>).T</span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>plt.plot(x, s)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-60-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>All the sample functions are:</p>
<ul>
<li>Smooth. While they repeat, the smoothness is like that of the ExpQuad, not the Matern52 or Matern32.</li>
<li>Periodic, but not sinusoidal.</li>
<li>Not necessarily mean zero. Again, you’re likely to see problems if they are included in a model with an intercept.</li>
</ul>
<section id="aside-applying-constraints" class="level3">
<h3 class="anchored" data-anchor-id="aside-applying-constraints">Aside: Applying constraints</h3>
<p>It’s possible to apply constraints to HSGPs as another way to resolve identifiability issues. There are two main possibilities:</p>
<ol type="1">
<li>Constrain the GP to have a mean of zero. There are two ways to do this:</li>
</ol>
<ul>
<li>Using <code>pm.Potential</code></li>
<li>De-meaning the basis vectors</li>
</ul>
<ol start="2" type="1">
<li>Constrain the GP to go to zero at the boundary. You can see this if you were to set `c=1 (try it!). It’s generally not recommended, unless it’s actually something you want to do.</li>
</ol>
<p>These are maybe a bit deeper in the bag of tricks, and we can add to this document if they come up in your situation.</p>
<p>Now let’s fit the same data but instead use the <code>HSGPPeridic</code> approximation model.</p>
<div id="2cb7668c-9a6e-4dcf-b8d2-9146fa1771d9" class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(<span class="dv">64</span>)</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>    alpha, U <span class="op">=</span> <span class="fl">0.1</span>, <span class="fl">5.0</span></span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a>    eta <span class="op">=</span> pm.Exponential(<span class="st">"eta"</span>, lam<span class="op">=-</span>np.log(alpha) <span class="op">/</span> U)</span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a>    ell <span class="op">=</span> pm.Lognormal(</span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"ell"</span>,</span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a>        <span class="op">**</span>pm.find_constrained_prior(</span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a>            pm.Lognormal,</span>
<span id="cb73-11"><a href="#cb73-11" aria-hidden="true" tabindex="-1"></a>            lower<span class="op">=</span><span class="fl">0.1</span>, upper<span class="op">=</span><span class="fl">5.0</span>, mass<span class="op">=</span><span class="fl">0.95</span>,</span>
<span id="cb73-12"><a href="#cb73-12" aria-hidden="true" tabindex="-1"></a>            init_guess<span class="op">=</span>{<span class="st">"mu"</span>: <span class="fl">5.0</span>, <span class="st">"sigma"</span>: <span class="fl">1.0</span>},</span>
<span id="cb73-13"><a href="#cb73-13" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb73-14"><a href="#cb73-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb73-15"><a href="#cb73-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-16"><a href="#cb73-16" aria-hidden="true" tabindex="-1"></a>    period <span class="op">=</span> <span class="fl">30.0</span></span>
<span id="cb73-17"><a href="#cb73-17" aria-hidden="true" tabindex="-1"></a>    cov_func <span class="op">=</span> pm.gp.cov.Periodic(input_dim<span class="op">=</span><span class="dv">1</span>, period<span class="op">=</span>period, ls<span class="op">=</span>ell)</span>
<span id="cb73-18"><a href="#cb73-18" aria-hidden="true" tabindex="-1"></a>    gp <span class="op">=</span> pm.gp.HSGPPeriodic(m<span class="op">=</span><span class="dv">50</span>, scale<span class="op">=</span>eta, cov_func<span class="op">=</span>cov_func)</span>
<span id="cb73-19"><a href="#cb73-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-20"><a href="#cb73-20" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> pm.Data(<span class="st">"X"</span>, x[:, <span class="va">None</span>])</span>
<span id="cb73-21"><a href="#cb73-21" aria-hidden="true" tabindex="-1"></a>    (phi_cos, phi_sin), psd <span class="op">=</span> gp.prior_linearized(X<span class="op">=</span>X)</span>
<span id="cb73-22"><a href="#cb73-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-23"><a href="#cb73-23" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> gp._m</span>
<span id="cb73-24"><a href="#cb73-24" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> pm.Normal(<span class="st">"beta"</span>, size<span class="op">=</span>(m <span class="op">*</span> <span class="dv">2</span> <span class="op">-</span> <span class="dv">1</span>))</span>
<span id="cb73-25"><a href="#cb73-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-26"><a href="#cb73-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The (non-centered) GP approximation is given by</span></span>
<span id="cb73-27"><a href="#cb73-27" aria-hidden="true" tabindex="-1"></a>    f <span class="op">=</span> pm.Deterministic(</span>
<span id="cb73-28"><a href="#cb73-28" aria-hidden="true" tabindex="-1"></a>        <span class="st">"f"</span>,</span>
<span id="cb73-29"><a href="#cb73-29" aria-hidden="true" tabindex="-1"></a>        phi_cos <span class="op">@</span> (psd <span class="op">*</span> beta[:m]) <span class="op">+</span> phi_sin[..., <span class="dv">1</span>:] <span class="op">@</span> (psd[<span class="dv">1</span>:] <span class="op">*</span> beta[m:])</span>
<span id="cb73-30"><a href="#cb73-30" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb73-31"><a href="#cb73-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb73-32"><a href="#cb73-32" aria-hidden="true" tabindex="-1"></a>    log_mu <span class="op">=</span> pm.Deterministic(<span class="st">"log_mu"</span>, f)</span>
<span id="cb73-33"><a href="#cb73-33" aria-hidden="true" tabindex="-1"></a>    pm.Poisson(<span class="st">"y"</span>, mu<span class="op">=</span>pt.exp(log_mu), observed<span class="op">=</span>y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="96083062-0129-44ce-9dc0-8f966803f5c3" class="cell" data-scrolled="true" data-execution_count="96">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> model:</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>    idata <span class="op">=</span> pm.sample(nuts_sampler<span class="op">=</span><span class="st">"numpyro"</span>, target_accept<span class="op">=</span><span class="fl">0.95</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8976d0c1742d45048dfec7c456191bc8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c54466b0681b49e29dde80ec55f296c6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"42336ff831314518bfcbaa374a259321","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"960792065fea4a8485adb9bcd9f22536","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
<div id="80eb2809-8b98-4a84-b253-0e3041c6476b" class="cell" data-execution_count="97">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>var_names <span class="op">=</span> [</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"eta"</span>,</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"ell"</span>,</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>az.summary(idata, var_names<span class="op">=</span>var_names)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="97">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">sd</th>
<th data-quarto-table-cell-role="th">hdi_3%</th>
<th data-quarto-table-cell-role="th">hdi_97%</th>
<th data-quarto-table-cell-role="th">mcse_mean</th>
<th data-quarto-table-cell-role="th">mcse_sd</th>
<th data-quarto-table-cell-role="th">ess_bulk</th>
<th data-quarto-table-cell-role="th">ess_tail</th>
<th data-quarto-table-cell-role="th">r_hat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">eta</td>
<td>5.449</td>
<td>2.377</td>
<td>1.899</td>
<td>9.902</td>
<td>0.048</td>
<td>0.034</td>
<td>1947.0</td>
<td>1957.0</td>
<td>1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">ell</td>
<td>2.195</td>
<td>0.515</td>
<td>1.330</td>
<td>3.212</td>
<td>0.009</td>
<td>0.007</td>
<td>2930.0</td>
<td>2487.0</td>
<td>1.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="ba3137e9-8395-46da-a0eb-3e8c4d83768c" class="cell" data-execution_count="98">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>x_new <span class="op">=</span> np.arange(<span class="dv">100</span>)</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> model:</span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>    pm.set_data({<span class="st">"X"</span>: x_new[:, <span class="va">None</span>]})</span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a>    idata.extend(pm.sample_posterior_predictive(idata, var_names<span class="op">=</span>[<span class="st">"log_mu"</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling: []</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9f229ea105c24146b5399748ab0fce3e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
</div>
<div id="5e9039a6-6494-40f3-a29e-43632d0ee44b" class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a>log_mu <span class="op">=</span> az.extract(idata.posterior_predictive, var_names<span class="op">=</span><span class="st">"log_mu"</span>).T</span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a>pm.gp.util.plot_gp_dist(ax<span class="op">=</span>ax, samples<span class="op">=</span>np.exp(log_mu), x<span class="op">=</span>x_new)<span class="op">;</span></span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a>ax.plot(x, f_true)<span class="op">;</span></span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a>ax.scatter(x, y, color<span class="op">=</span><span class="st">"c"</span>)<span class="op">;</span></span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a>ax.set_xlim([<span class="dv">0</span>, np.<span class="bu">max</span>(x_new)])</span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a>ax.set_ylim([<span class="dv">0</span>, <span class="dv">20</span>])<span class="op">;</span></span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"posterior of f"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-65-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Much better! Two cycles was enough to pick up the repeating behavior. Each peak in the fit is exactly like the others, where with the non-periodic HSGP they werent. You’ll also notice that the forecast doesnt revert to the prior, because that’s a feature of Matern kernels and not of something like a periodic kernel.</p>
</section>
<section id="setting-the-lengthscale-prior-for-a-periodic-gp" class="level2">
<h2 class="anchored" data-anchor-id="setting-the-lengthscale-prior-for-a-periodic-gp">Setting the lengthscale prior for a periodic GP</h2>
<p>The lengthscale controls how flexible the GP is within a period. I don’t know of any papers or recommendations out there for how to choose it in the context of periodic GPs. The values that work end up being a lot smaller than I would expect, so I’m not sure on the precise interpretation. I think it’s less important than for Matern family GPs because it’s in a periodic GP the period is the more important quantity. Note that you can set a prior on the period and not use a fixed value, but the sampler will have a hard time and you likely do know the period in most contexts.</p>
<p>Since you’re telling the GP that it’s looking at many repetition of the same pattern, the lengthscale is usually quite a bit easier to learn. Just remember when setting it that it’s going to be a much smaller value than you’d expect, and be sure to check the prior predictive distribution of the GP samples at a few different values of the lengthscale, like the one’s we’ll look at below.</p>
<section id="prior-samples-where-the-lengthscale-is-drawn-from-a-prior" class="level3">
<h3 class="anchored" data-anchor-id="prior-samples-where-the-lengthscale-is-drawn-from-a-prior">Prior samples where the lengthscale is drawn from a prior</h3>
<div id="42311917-d11f-434b-b895-d5e75b820bf7" class="cell" data-execution_count="112">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(<span class="dv">64</span>)</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a>    alpha, U <span class="op">=</span> <span class="fl">0.1</span>, <span class="fl">5.0</span></span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a>    eta <span class="op">=</span> pm.Exponential(<span class="st">"eta"</span>, lam<span class="op">=-</span>np.log(alpha) <span class="op">/</span> U)</span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>    ell <span class="op">=</span> pm.Lognormal(</span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"ell"</span>,</span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a>        <span class="op">**</span>pm.find_constrained_prior(</span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a>            pm.Lognormal,</span>
<span id="cb79-11"><a href="#cb79-11" aria-hidden="true" tabindex="-1"></a>            lower<span class="op">=</span><span class="fl">0.5</span>, upper<span class="op">=</span><span class="fl">5.0</span>, mass<span class="op">=</span><span class="fl">0.95</span>,</span>
<span id="cb79-12"><a href="#cb79-12" aria-hidden="true" tabindex="-1"></a>            init_guess<span class="op">=</span>{<span class="st">"mu"</span>: <span class="fl">5.0</span>, <span class="st">"sigma"</span>: <span class="fl">1.0</span>},</span>
<span id="cb79-13"><a href="#cb79-13" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb79-14"><a href="#cb79-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb79-15"><a href="#cb79-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-16"><a href="#cb79-16" aria-hidden="true" tabindex="-1"></a>    period <span class="op">=</span> <span class="fl">30.0</span></span>
<span id="cb79-17"><a href="#cb79-17" aria-hidden="true" tabindex="-1"></a>    cov_func <span class="op">=</span> pm.gp.cov.Periodic(input_dim<span class="op">=</span><span class="dv">1</span>, period<span class="op">=</span>period, ls<span class="op">=</span>ell)</span>
<span id="cb79-18"><a href="#cb79-18" aria-hidden="true" tabindex="-1"></a>    gp <span class="op">=</span> pm.gp.HSGPPeriodic(m<span class="op">=</span><span class="dv">50</span>, scale<span class="op">=</span>eta, cov_func<span class="op">=</span>cov_func)</span>
<span id="cb79-19"><a href="#cb79-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb79-20"><a href="#cb79-20" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> pm.Data(<span class="st">"X"</span>, x[:, <span class="va">None</span>])</span>
<span id="cb79-21"><a href="#cb79-21" aria-hidden="true" tabindex="-1"></a>    (phi_cos, phi_sin), psd <span class="op">=</span> gp.prior_linearized(X<span class="op">=</span>X)</span>
<span id="cb79-22"><a href="#cb79-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-23"><a href="#cb79-23" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> gp._m</span>
<span id="cb79-24"><a href="#cb79-24" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> pm.Normal(<span class="st">"beta"</span>, size<span class="op">=</span>(m <span class="op">*</span> <span class="dv">2</span> <span class="op">-</span> <span class="dv">1</span>))</span>
<span id="cb79-25"><a href="#cb79-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-26"><a href="#cb79-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The (non-centered) GP approximation is given by</span></span>
<span id="cb79-27"><a href="#cb79-27" aria-hidden="true" tabindex="-1"></a>    f <span class="op">=</span> pm.Deterministic(</span>
<span id="cb79-28"><a href="#cb79-28" aria-hidden="true" tabindex="-1"></a>        <span class="st">"f"</span>,</span>
<span id="cb79-29"><a href="#cb79-29" aria-hidden="true" tabindex="-1"></a>        phi_cos <span class="op">@</span> (psd <span class="op">*</span> beta[:m]) <span class="op">+</span> phi_sin[..., <span class="dv">1</span>:] <span class="op">@</span> (psd[<span class="dv">1</span>:] <span class="op">*</span> beta[m:])</span>
<span id="cb79-30"><a href="#cb79-30" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb79-31"><a href="#cb79-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb79-32"><a href="#cb79-32" aria-hidden="true" tabindex="-1"></a>    idata <span class="op">=</span> pm.sample_prior_predictive()</span>
<span id="cb79-33"><a href="#cb79-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-34"><a href="#cb79-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-35"><a href="#cb79-35" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> az.extract(idata.prior, var_names<span class="op">=</span><span class="st">"f"</span>).data</span>
<span id="cb79-36"><a href="#cb79-36" aria-hidden="true" tabindex="-1"></a>plt.plot(f[:, :<span class="dv">20</span>])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling: [beta, ell, eta]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-66-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="prior-samples-with-a-small-lengthscale" class="level3">
<h3 class="anchored" data-anchor-id="prior-samples-with-a-small-lengthscale">Prior samples with a small lengthscale</h3>
<div id="98cfa4cd-f56f-43e8-863e-f5f4af8b706a" class="cell" data-execution_count="110">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.do(model, {<span class="st">"ell"</span>: <span class="fl">0.5</span>}) <span class="im">as</span> model:</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>    idata <span class="op">=</span> pm.sample_prior_predictive()</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>    f <span class="op">=</span> az.extract(idata.prior, var_names<span class="op">=</span><span class="st">"f"</span>).data</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>    plt.plot(f[:, :<span class="dv">5</span>])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling: [beta, eta]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-67-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="prior-samples-with-a-large-lengthscale" class="level3">
<h3 class="anchored" data-anchor-id="prior-samples-with-a-large-lengthscale">Prior samples with a large lengthscale</h3>
<div id="5d7fe0eb-05db-47d2-bca4-df3cfd0027c3" class="cell" data-execution_count="116">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.do(model, {<span class="st">"ell"</span>:  <span class="dv">3</span>}) <span class="im">as</span> model:</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>    idata <span class="op">=</span> pm.sample_prior_predictive()</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>    f <span class="op">=</span> az.extract(idata.prior, var_names<span class="op">=</span><span class="st">"f"</span>).data</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>    plt.plot(f[:, :<span class="dv">5</span>])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling: [beta, eta]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-68-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Larger lengthscales are much more “sinusoidal” so there’s no variation within a cycle, and smaller lengthscales vary much more. Overall, I’d recommend not necessarily following the “inverse gamma is good” rule for lengthscales on periodic GPs. Truncated normals (lengthscales still must be positive) or gamma distributions might work better.</p>
<p>You’ll notice the intercept problem is much more pronounced with periodic GPs, particularly for larger lengthscales. I think having a heavy right tail on the prior in this situation would be harmful.</p>
</section>
<section id="why-do-periodic-gps-involve-more-of-a-level-shift" class="level3">
<h3 class="anchored" data-anchor-id="why-do-periodic-gps-involve-more-of-a-level-shift">Why do Periodic GPs involve more of a level shift?</h3>
<p>You can see why in this plot from earlier, which compared the covariance as a function of distance.</p>
<div id="127d0b84-cd3a-4864-80c9-dd89cc8a2252" class="cell" data-execution_count="117">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">100</span>)</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>cov1 <span class="op">=</span> pm.gp.cov.Matern52(<span class="dv">1</span>, ls<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>cov2 <span class="op">=</span> pm.gp.cov.Periodic(<span class="dv">1</span>, period<span class="op">=</span><span class="dv">3</span>, ls<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>K1 <span class="op">=</span> cov1(x[:, <span class="va">None</span>])</span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a>K2 <span class="op">=</span> cov2(x[:, <span class="va">None</span>])</span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a>plt.plot(x, K1[:, <span class="dv">0</span>].<span class="bu">eval</span>(), label<span class="op">=</span><span class="st">"Matern52"</span>)</span>
<span id="cb85-10"><a href="#cb85-10" aria-hidden="true" tabindex="-1"></a>plt.plot(x, K2[:, <span class="dv">0</span>].<span class="bu">eval</span>(), label<span class="op">=</span><span class="st">"Periodic"</span>)<span class="op">;</span></span>
<span id="cb85-11"><a href="#cb85-11" aria-hidden="true" tabindex="-1"></a>plt.legend()<span class="op">;</span></span>
<span id="cb85-12"><a href="#cb85-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"covariance"</span>)<span class="op">;</span></span>
<span id="cb85-13"><a href="#cb85-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"x distance"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-69-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Notice that the covariance never goes to zero for the Periodic example. That means that all points in the GP have a non-negligible covariance with all the other points. This is equivalent to an intercept. It’s kind of strange at first but it does make sense. You can see this by drawing samples from a multivariate normal who’s covariance matrix is just a square matrix of all ones.</p>
<div id="52129ff1-0a84-4071-813b-6cd433eb0c0c" class="cell" data-execution_count="133">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>K <span class="op">=</span> np.ones((<span class="dv">100</span>,<span class="dv">100</span>))</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> pm.draw(pm.MvNormal.dist(mu<span class="op">=</span>np.zeros(<span class="dv">100</span>), cov<span class="op">=</span>K), <span class="dv">5</span>).T</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>plt.plot(s)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-70-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>To see how this shows up for the periodic covariance matrix, we’ll remake an earlier figure but with different values of the covariance. This plot shows the covariance as a function the distance between two x values, x and x’. At small lengthscales the covariance goes to zero at some distances. As the lenthscale increases, the covariance stays positive everywhere. When there’s a non-negligible covariance everywhere, that allows the level of the GP to shift up and down. It’s something to be mindful of when setting priors on the GP lengthscales, and on whether you should include an intercept parameter with the GP.</p>
<div id="96dfd5e9-6189-467f-9afc-1bf613f56596" class="cell" data-execution_count="127">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">100</span>)</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>cov0 <span class="op">=</span> pm.gp.cov.Periodic(<span class="dv">1</span>, period<span class="op">=</span><span class="dv">3</span>, ls<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>cov1 <span class="op">=</span> pm.gp.cov.Periodic(<span class="dv">1</span>, period<span class="op">=</span><span class="dv">3</span>, ls<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a>cov2 <span class="op">=</span> pm.gp.cov.Periodic(<span class="dv">1</span>, period<span class="op">=</span><span class="dv">3</span>, ls<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a>cov3 <span class="op">=</span> pm.gp.cov.Periodic(<span class="dv">1</span>, period<span class="op">=</span><span class="dv">3</span>, ls<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-8"><a href="#cb87-8" aria-hidden="true" tabindex="-1"></a>K0 <span class="op">=</span> cov0(x[:, <span class="va">None</span>])</span>
<span id="cb87-9"><a href="#cb87-9" aria-hidden="true" tabindex="-1"></a>K1 <span class="op">=</span> cov1(x[:, <span class="va">None</span>])</span>
<span id="cb87-10"><a href="#cb87-10" aria-hidden="true" tabindex="-1"></a>K2 <span class="op">=</span> cov2(x[:, <span class="va">None</span>])</span>
<span id="cb87-11"><a href="#cb87-11" aria-hidden="true" tabindex="-1"></a>K3 <span class="op">=</span> cov3(x[:, <span class="va">None</span>])</span>
<span id="cb87-12"><a href="#cb87-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-13"><a href="#cb87-13" aria-hidden="true" tabindex="-1"></a>plt.plot(x, K0[:, <span class="dv">0</span>].<span class="bu">eval</span>(), label<span class="op">=</span><span class="st">"ls=0.2"</span>)</span>
<span id="cb87-14"><a href="#cb87-14" aria-hidden="true" tabindex="-1"></a>plt.plot(x, K1[:, <span class="dv">0</span>].<span class="bu">eval</span>(), label<span class="op">=</span><span class="st">"ls=0.3"</span>)</span>
<span id="cb87-15"><a href="#cb87-15" aria-hidden="true" tabindex="-1"></a>plt.plot(x, K2[:, <span class="dv">0</span>].<span class="bu">eval</span>(), label<span class="op">=</span><span class="st">"ls=0.4"</span>)<span class="op">;</span></span>
<span id="cb87-16"><a href="#cb87-16" aria-hidden="true" tabindex="-1"></a>plt.plot(x, K3[:, <span class="dv">0</span>].<span class="bu">eval</span>(), label<span class="op">=</span><span class="st">"ls=0.5"</span>)<span class="op">;</span></span>
<span id="cb87-17"><a href="#cb87-17" aria-hidden="true" tabindex="-1"></a>plt.legend()<span class="op">;</span></span>
<span id="cb87-18"><a href="#cb87-18" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"covariance"</span>)<span class="op">;</span></span>
<span id="cb87-19"><a href="#cb87-19" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"x distance"</span>)<span class="op">;</span></span>
<span id="cb87-20"><a href="#cb87-20" aria-hidden="true" tabindex="-1"></a>plt.axhline(y<span class="op">=</span><span class="dv">0</span>, color<span class="op">=</span><span class="st">"k"</span>, linestyle<span class="op">=</span><span class="st">":"</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-71-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>But, there is a trick we can use to enforce the periodic GP to have zero mean. It’s no longer mathematically GP with a periodic covariance function, it’s something else that’s similar but not exactly the same.</p>
</section>
</section>
</section>
<section id="setting-constraints" class="level1">
<h1>Setting constraints</h1>
<p>There are a few constraints available for setting on GPs. The problem is that most of them make it so you can’t forecast with the GP anymore. The constraint only helps you remove identifiability in your model on the specific data set your fitting. We’re starting a little project here to make it easier to apply some of these constraints to HSGP models <a href="https://github.com/maresb/pymc-gpx">here</a> but the code is far from usable.</p>
<section id="zero-mean-constraints-periodic-gp" class="level2">
<h2 class="anchored" data-anchor-id="zero-mean-constraints-periodic-gp">Zero mean constraints, periodic GP</h2>
<p>We’ll start with the zero mean constraint for the periodic GP, since this is likely to be the most useful to you. To enforce the constraint, simply subtract the mean from each of the sine and cosine basis vectors.</p>
<div id="4e0c9c44-5a2b-4a0e-b202-754b6d475041" class="cell" data-execution_count="140">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(<span class="dv">64</span>)</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>    alpha, U <span class="op">=</span> <span class="fl">0.1</span>, <span class="fl">5.0</span></span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a>    eta <span class="op">=</span> pm.Exponential(<span class="st">"eta"</span>, lam<span class="op">=-</span>np.log(alpha) <span class="op">/</span> U)</span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a>    ell <span class="op">=</span> pm.Lognormal(</span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"ell"</span>,</span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a>        <span class="op">**</span>pm.find_constrained_prior(</span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a>            pm.Lognormal,</span>
<span id="cb88-11"><a href="#cb88-11" aria-hidden="true" tabindex="-1"></a>            lower<span class="op">=</span><span class="fl">0.5</span>, upper<span class="op">=</span><span class="fl">5.0</span>, mass<span class="op">=</span><span class="fl">0.95</span>,</span>
<span id="cb88-12"><a href="#cb88-12" aria-hidden="true" tabindex="-1"></a>            init_guess<span class="op">=</span>{<span class="st">"mu"</span>: <span class="fl">5.0</span>, <span class="st">"sigma"</span>: <span class="fl">1.0</span>},</span>
<span id="cb88-13"><a href="#cb88-13" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb88-14"><a href="#cb88-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb88-15"><a href="#cb88-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-16"><a href="#cb88-16" aria-hidden="true" tabindex="-1"></a>    period <span class="op">=</span> <span class="fl">30.0</span></span>
<span id="cb88-17"><a href="#cb88-17" aria-hidden="true" tabindex="-1"></a>    cov_func <span class="op">=</span> pm.gp.cov.Periodic(input_dim<span class="op">=</span><span class="dv">1</span>, period<span class="op">=</span>period, ls<span class="op">=</span>ell)</span>
<span id="cb88-18"><a href="#cb88-18" aria-hidden="true" tabindex="-1"></a>    gp <span class="op">=</span> pm.gp.HSGPPeriodic(m<span class="op">=</span><span class="dv">50</span>, scale<span class="op">=</span>eta, cov_func<span class="op">=</span>cov_func)</span>
<span id="cb88-19"><a href="#cb88-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb88-20"><a href="#cb88-20" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> pm.Data(<span class="st">"X"</span>, x[:, <span class="va">None</span>])</span>
<span id="cb88-21"><a href="#cb88-21" aria-hidden="true" tabindex="-1"></a>    (phi_cos, phi_sin), psd <span class="op">=</span> gp.prior_linearized(X<span class="op">=</span>X)</span>
<span id="cb88-22"><a href="#cb88-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-23"><a href="#cb88-23" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> gp._m</span>
<span id="cb88-24"><a href="#cb88-24" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> pm.Normal(<span class="st">"beta"</span>, size<span class="op">=</span>(m <span class="op">*</span> <span class="dv">2</span> <span class="op">-</span> <span class="dv">1</span>))</span>
<span id="cb88-25"><a href="#cb88-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-26"><a href="#cb88-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># subtract the mean from each of the basis vectors</span></span>
<span id="cb88-27"><a href="#cb88-27" aria-hidden="true" tabindex="-1"></a>    phi_cos <span class="op">=</span> phi_cos <span class="op">-</span> pt.mean(phi_cos, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb88-28"><a href="#cb88-28" aria-hidden="true" tabindex="-1"></a>    phi_sin <span class="op">=</span> phi_sin <span class="op">-</span> pt.mean(phi_sin, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb88-29"><a href="#cb88-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb88-30"><a href="#cb88-30" aria-hidden="true" tabindex="-1"></a>    f <span class="op">=</span> pm.Deterministic(</span>
<span id="cb88-31"><a href="#cb88-31" aria-hidden="true" tabindex="-1"></a>        <span class="st">"f"</span>,</span>
<span id="cb88-32"><a href="#cb88-32" aria-hidden="true" tabindex="-1"></a>        phi_cos <span class="op">@</span> (psd <span class="op">*</span> beta[:m]) <span class="op">+</span> phi_sin[..., <span class="dv">1</span>:] <span class="op">@</span> (psd[<span class="dv">1</span>:] <span class="op">*</span> beta[m:])</span>
<span id="cb88-33"><a href="#cb88-33" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb88-34"><a href="#cb88-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb88-35"><a href="#cb88-35" aria-hidden="true" tabindex="-1"></a>    idata <span class="op">=</span> pm.sample_prior_predictive()</span>
<span id="cb88-36"><a href="#cb88-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-37"><a href="#cb88-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-38"><a href="#cb88-38" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> az.extract(idata.prior, var_names<span class="op">=</span><span class="st">"f"</span>).data</span>
<span id="cb88-39"><a href="#cb88-39" aria-hidden="true" tabindex="-1"></a>plt.plot(f[:, :<span class="dv">20</span>])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling: [beta, ell, eta]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-72-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Now you can see that all the samples from the GP hover around zero much better. If you calculate the mean of each sample you’ll see they are all nearly exactly zero. I think this is worth trying whenever you need to use a Periodic HSGP, and maybe it should be part of the PyMC code…</p>
</section>
<section id="zero-mean-constraints-regular-hsgps" class="level2">
<h2 class="anchored" data-anchor-id="zero-mean-constraints-regular-hsgps">Zero mean constraints, regular HSGPs</h2>
<p>You can use the exact same trick for regular HSGPs too, subtract the mean from each of the basis vectors. To do so you’ll have to write a little custom code, but overall it’s pretty straightforward to do. The place to start is by reading the source for <code>HSGP.prior_linearized</code>. I’ll skip doing that here because I suspect it’ll be less useful for your usecase. If you enforce the HSGP to have exactly zero mean, you won’t be able to use it to forecast. If you don’t need to forecast into the future, and you still do need the constraint, I’d suggest switching to splines. The <a href="https://patsy.readthedocs.io/en/latest/spline-regression.html">patsy documentation</a> (though it’s not super explicit) shows how to apply zero mean, monotonic increasing and decreasing, and periodic constraints to spline functions.</p>
<p>A super fast trick I sometimes use to apply a zero mean constraint (though it doesn’t always work), is to use a <code>Potential</code> to add a “soft” zero mean constraint. The code to force a variable <code>x</code> to have zero mean is:</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>pm.Potential(<span class="st">"constraint"</span>, pm.logp(pm.Normal.dist(mu<span class="op">=</span><span class="fl">0.0</span>, sigma<span class="op">=</span><span class="fl">0.001</span>), pt.mean(x)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Translated into english, what this says is:</p>
<p>“Add a term to the log likelihood that puts a normal prior, with mean zero and small sigma, on the mean of <code>x</code>”. This penalizes deviations of the mean of x away from zero. This can be a bit touchy where you may have to fidle with the value of sigma, but this trick can be useful sometimes, mostly because it’s so easy to apply and you can apply it to any vector without too much thought.</p>
</section>
</section>
<section id="logging-the-output-and-the-log-normal-likelihood" class="level1">
<h1>Logging the output and the log-normal likelihood</h1>
<p>The lognormal distribution can be used to model data that is takes only positive real values (so not integers). There are a few likelihoods that are commonly used. The log-normal isn’t terribly common for some reason, but I think it’s straightforward to use and useful. It’s definition is:</p>
<p>If <span class="math inline">\(X \sim N(\mu, \sigma^2)\)</span>, then <span class="math inline">\(\exp(X) \sim \text{LogNormal}(\mu, \sigma)\)</span>. <a href="https://en.wikipedia.org/wiki/Log-normal_distribution">Wikipedia</a> lists it’s properties. Some important for using it as a likelihood:</p>
<ul>
<li>It has the <span class="math inline">\(\exp\)</span> function “built-in”. That means that if you plug zero into it, it’s center (for a log-normal, this is the median) is one.</li>
<li>It makes regression models multiplicative. This is what happens when you exponentiate a simple linear regression model,</li>
</ul>
<p><span class="math display">\[
\begin{align}
\log{y} &amp;= \beta_0 + \beta_1 x \\
y &amp;= \exp{(\beta_0 + \beta_1 x)} \\
  &amp;= \exp{(\beta_0}) \exp{(\beta_1 x)} \\
  &amp;= \text{baseline} \cdot \text{multiplicative factors} \\
\end{align}
\]</span> So you can interpret the quantity <span class="math inline">\(\exp{(\beta_0})\)</span> as your models “intercept” or “baseline”, and the other factors in model as multiplicative adjustments up or down, based on whether they are above or below 1. This is important to know when setting priors. Things work out nicely though. A prior on a parameter centered at zero, when exponentiated now has a median of one – meaning it’s equally likely to be an increasing (above one) or decreaseing (below one) adjustment of the baseline.</p>
<p>Using a log-normal likelihood is equivalent to taking the log of your <span class="math inline">\(y\)</span> variable and running your model with a normal likelihood. The coefficient interpretations aren’t different. The advantage of using the log-normal likelihood is that all of your prior and posterior predictives, your cross-validation estimates, everything downstream of the model remains in the natural un-logged scale of <span class="math inline">\(y\)</span>. This keeps your interpretation of the model more generative.</p>
<section id="other-very-common-likelihoods" class="level3">
<h3 class="anchored" data-anchor-id="other-very-common-likelihoods">Other very common likelihoods:</h3>
<p>Always good to keep an eye out for these.</p>
<ul>
<li>Poisson / Negative Binomial: y data are integer valued counts. You can use a normal if the counts are large, but if zero’s are involved, you definitely need to use one of these likelihoods. These likelihoods should also be used for rates – events per unit of exposure. For example, employee A had 3 injuries over 10 years or employment. Employee B had 1 injury over 6 months.<br>
</li>
<li>Binomial: k of n type data. The baseball player had 100 at bats, and hits on 30 of them.</li>
<li>Bernoulli / Binomial: 0 or 1 data. Logistic regression. “classification”.</li>
</ul>
<div id="35869815-4418-4443-9990-d7810c953e96" class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pytensor.tensor <span class="im">as</span> pt</span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nutpie</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here’s a scenario. There’s a study with 100 patients who are experimenting with a drug that makes them smarter (dumb example but whatever). Half are given the drug and half are given a placebo. At the start of the study they all score a 0.01. For the group that takes the drug, their score increased by a factor of 1.2 on average. So a the end of the study they scored 0.012 on average . The lognormal likelihood is appropriate here because we: 1. Want to measure a multiplicative effect of the treatment. The treatment doesn’t add a fixed value to everyones score, like an additive model suggests, instead it makes everyone 20% smarter. 2. Test scores are non-negative, at least for this example.</p>
<p>To apply this model for the MMM, you would need to have a baseline effect on sales that marketing spends increase or decrease multiplicatively. I think this is actually pretty similar to what you’re currently doing with the periodic component now. If you implemented this you’d have to think carefully how this relates to saturation, I’m not sure.</p>
<p>This data is generated below, according to the lognormal likelihood.</p>
<div id="162a320a-e3f6-47db-9a40-20e34add58ce" class="cell" data-execution_count="144">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>RANDOM_SEED <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(RANDOM_SEED)</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.concatenate((</span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a>    np.zeros(<span class="dv">50</span>),</span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>    np.ones(<span class="dv">50</span>),</span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a>))</span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a>c0_true <span class="op">=</span> np.log(<span class="fl">0.01</span>)</span>
<span id="cb92-9"><a href="#cb92-9" aria-hidden="true" tabindex="-1"></a>c1_true <span class="op">=</span> np.log(<span class="fl">1.2</span>)</span>
<span id="cb92-10"><a href="#cb92-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-11"><a href="#cb92-11" aria-hidden="true" tabindex="-1"></a><span class="co"># define the generative process</span></span>
<span id="cb92-12"><a href="#cb92-12" aria-hidden="true" tabindex="-1"></a>sigma_true <span class="op">=</span> <span class="fl">0.3</span> <span class="co"># because they aren't all exactly the same height and we want the average treatment effect</span></span>
<span id="cb92-13"><a href="#cb92-13" aria-hidden="true" tabindex="-1"></a>y_dist <span class="op">=</span> pm.Lognormal.dist(mu<span class="op">=</span>c0_true <span class="op">+</span> c1_true <span class="op">*</span> x, sigma<span class="op">=</span>sigma_true)</span>
<span id="cb92-14"><a href="#cb92-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-15"><a href="#cb92-15" aria-hidden="true" tabindex="-1"></a><span class="co"># draw one replication of the entire dataset</span></span>
<span id="cb92-16"><a href="#cb92-16" aria-hidden="true" tabindex="-1"></a>y_obs <span class="op">=</span> pm.draw(y_dist, random_seed<span class="op">=</span>rng)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="e6f8af3b-19a2-4659-a495-69b7a102126c" class="cell" data-execution_count="145">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>plt.plot(x, y_obs, <span class="st">'.'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-77-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Now let’s recover the true values using PyMC.</p>
<div id="9e4e0ef5-c51c-4d69-bf8d-2c0779afd5fe" class="cell" data-execution_count="146">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>    c0 <span class="op">=</span> pm.Normal(<span class="st">"c0"</span>, mu<span class="op">=</span><span class="fl">0.0</span>, sigma<span class="op">=</span><span class="fl">10.0</span>)</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>    c1 <span class="op">=</span> pm.Normal(<span class="st">"c1"</span>, mu<span class="op">=</span><span class="fl">0.0</span>, sigma<span class="op">=</span><span class="fl">5.0</span>)</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a>    linear_predictor <span class="op">=</span> c0 <span class="op">+</span> c1 <span class="op">*</span> x</span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> pm.Exponential(<span class="st">"sigma"</span>, scale<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a>    pm.Lognormal(<span class="st">"y"</span>, mu<span class="op">=</span>linear_predictor, sigma<span class="op">=</span>sigma, observed<span class="op">=</span>y_obs)</span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a>    idata <span class="op">=</span> pm.sample()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [c0, c1, sigma]</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"aed64350c5854007944ab3bcd7fe467a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 20 seconds.</code></pre>
</div>
</div>
<div id="b25f21ca-7af6-447b-b283-1d06ce8496e8" class="cell" data-execution_count="147">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>az.plot_trace(idata)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-79-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The model recovers the true values correctly.</p>
<div id="55c30d91-2fab-4869-a8b6-7f1a3e2bb66d" class="cell" data-execution_count="148">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(c0_true, c1_true, sigma_true)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>-4.605170185988091 0.1823215567939546 0.3</code></pre>
</div>
</div>
<p>When we take a look at the posterior predictives, we get values on the original scale of <span class="math inline">\(y\)</span> with no chance of getting <span class="math inline">\(y\)</span> values that are below zero. You can see the characteristic shape where the posterior predictive samples have the long right tail, and a left tail that gets scrunched into zero. This is why we suggested this likelihood when we saw your PPC plot.</p>
<div id="8656e1b7-a409-41ee-8436-896cbb6cb942" class="cell" data-execution_count="149">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> model:</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>    pm.sample_posterior_predictive(idata, extend_inferencedata<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling: [y]</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e7a1a863e9574e8884be7b71e34d078b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
</div>
<div id="392a7be2-19f6-408f-8e26-f0f1f17b5083" class="cell" data-execution_count="150">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>az.plot_ppc(idata)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11-03-2024_how-to-fit-a-GP_files/figure-html/cell-82-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="bonus-a-log-student-t-likelihood" class="level1">
<h1>Bonus: a log-student-t likelihood</h1>
<p>Just like a student-t likelihood can “robustify” a normal likelihood in the presence of outliers, we can do the same with the log-normal likelihood. This code isn’t implemented as part of PyMC (although maybe it should be?). At this point, this is <strong>not</strong> the same as logging <span class="math inline">\(y\)</span>, this is something a little different (and better!). Credit to Jesse or Ricardo or Alex F not sure I stole it from their code.</p>
<div id="52ec2d85-3be2-46ec-8a3e-9476aae82813" class="cell">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_student_t(nu, mu, sigma, shape<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pm.math.exp(pm.StudentT.dist(mu<span class="op">=</span>mu, sigma<span class="op">=</span>sigma, nu<span class="op">=</span>nu, shape<span class="op">=</span>shape))</span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a>llike <span class="op">=</span> pm.CustomDist(</span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"C_wd"</span>,</span>
<span id="cb103-6"><a href="#cb103-6" aria-hidden="true" tabindex="-1"></a>    nu,</span>
<span id="cb103-7"><a href="#cb103-7" aria-hidden="true" tabindex="-1"></a>    mu,</span>
<span id="cb103-8"><a href="#cb103-8" aria-hidden="true" tabindex="-1"></a>    sigma,</span>
<span id="cb103-9"><a href="#cb103-9" aria-hidden="true" tabindex="-1"></a>    observed<span class="op">=</span>y_obs,</span>
<span id="cb103-10"><a href="#cb103-10" aria-hidden="true" tabindex="-1"></a>    shape<span class="op">=</span>mu.shape,</span>
<span id="cb103-11"><a href="#cb103-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">#dims=["obs_idx"], # dims you might be using for your observed data</span></span>
<span id="cb103-12"><a href="#cb103-12" aria-hidden="true" tabindex="-1"></a>    dist<span class="op">=</span>log_student_t,</span>
<span id="cb103-13"><a href="#cb103-13" aria-hidden="true" tabindex="-1"></a>    class_name<span class="op">=</span><span class="st">"LogStudentT"</span>,</span>
<span id="cb103-14"><a href="#cb103-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb103-15"><a href="#cb103-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Monkey patching for textual representation until this is solved in PyMC, for graphviz</span></span>
<span id="cb103-16"><a href="#cb103-16" aria-hidden="true" tabindex="-1"></a>llike.owner.op._print_name <span class="op">=</span> (<span class="st">"LogStudentT"</span>, <span class="st">"</span><span class="ch">\\</span><span class="st">operatorname</span><span class="sc">{LogStudentT}</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="crossvalidation" class="level1">
<h1>Crossvalidation</h1>
<p>The best resource / roadmap for cross-validation that I know of is on <a href="https://users.aalto.fi/~ave/CV-FAQ.html">Aki Vehtari’s page</a>. Actually everything on his page is excellent. For time series crossvalidation, we’d recommend LFO (leave future out) crossvalidation, as per <a href="https://arxiv.org/abs/1902.06281">this paper</a>. Looks like there was an effort to <a href="https://github.com/arviz-devs/arviz/issues/2068">get this into Arviz here</a> that may have stalled out. I can check in with Jesse and cmgoold to see what happened.</p>
<p>There’s a few things to note first: 1. Exact crossvalidation is literally taking hold out sets and refitting the model k times. If you’re doing LOO (leave one out), you refit for every data point you have. This is computationally expensive.<br>
2. <em>Approximate</em> crossvalidation is what PyMC and Arviz implement. The Pareto k-hat values indicate data points whose ELPD <em>wasn’t well approximated</em>, and so the model actually needs to be refit with that point held out to fix this. I think lots of people are lazy and don’t bother… though they should. 3. LFO crossvalidation in the paper I referenced is also an approximation.<br>
4. Depending on the scenario you want to test it <em>may</em> be better to just refit everything and not mess with implementing the approximation. Cloud compute is a lot cheaper than developer time. Your laptop probably isn’t up for it though.</p>
<p>Approximate leave-one-out crossvalidation is pretty trivial to implement in PyMC. Even though the carryover effects and the fact that you’re working with a time series means LOO assumptions are definitely invalid, I think it’s not going to be wildly wrong to start there. Let’s define two models using the previous example. One with the normal likelihood, one with the log-t.</p>
<div id="8382622c-35a2-41d3-aa4d-aefa09c8a569" class="cell" data-execution_count="155">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model1:</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>    c0 <span class="op">=</span> pm.Normal(<span class="st">"c0"</span>, mu<span class="op">=</span><span class="fl">0.0</span>, sigma<span class="op">=</span><span class="fl">10.0</span>)</span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>    c1 <span class="op">=</span> pm.Normal(<span class="st">"c1"</span>, mu<span class="op">=</span><span class="fl">0.0</span>, sigma<span class="op">=</span><span class="fl">5.0</span>)</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a>    linear_predictor <span class="op">=</span> c0 <span class="op">+</span> c1 <span class="op">*</span> x</span>
<span id="cb104-6"><a href="#cb104-6" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> pm.Exponential(<span class="st">"sigma"</span>, scale<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb104-7"><a href="#cb104-7" aria-hidden="true" tabindex="-1"></a>    pm.Lognormal(<span class="st">"y"</span>, mu<span class="op">=</span>linear_predictor, sigma<span class="op">=</span>sigma, observed<span class="op">=</span>y_obs)</span>
<span id="cb104-8"><a href="#cb104-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-9"><a href="#cb104-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-10"><a href="#cb104-10" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model2:</span>
<span id="cb104-11"><a href="#cb104-11" aria-hidden="true" tabindex="-1"></a>    c0 <span class="op">=</span> pm.Normal(<span class="st">"c0"</span>, mu<span class="op">=</span><span class="fl">0.0</span>, sigma<span class="op">=</span><span class="fl">10.0</span>)</span>
<span id="cb104-12"><a href="#cb104-12" aria-hidden="true" tabindex="-1"></a>    c1 <span class="op">=</span> pm.Normal(<span class="st">"c1"</span>, mu<span class="op">=</span><span class="fl">0.0</span>, sigma<span class="op">=</span><span class="fl">5.0</span>)</span>
<span id="cb104-13"><a href="#cb104-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-14"><a href="#cb104-14" aria-hidden="true" tabindex="-1"></a>    linear_predictor <span class="op">=</span> c0 <span class="op">+</span> c1 <span class="op">*</span> x</span>
<span id="cb104-15"><a href="#cb104-15" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> pm.Exponential(<span class="st">"sigma"</span>, scale<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb104-16"><a href="#cb104-16" aria-hidden="true" tabindex="-1"></a>    nu <span class="op">=</span> pm.Gamma(<span class="st">"nu"</span>, alpha<span class="op">=</span><span class="dv">2</span>, beta<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb104-17"><a href="#cb104-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-18"><a href="#cb104-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> log_student_t(nu, mu, sigma, shape<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb104-19"><a href="#cb104-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> pm.math.exp(pm.StudentT.dist(mu<span class="op">=</span>mu, sigma<span class="op">=</span>sigma, nu<span class="op">=</span>nu, shape<span class="op">=</span>shape))</span>
<span id="cb104-20"><a href="#cb104-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-21"><a href="#cb104-21" aria-hidden="true" tabindex="-1"></a>    llike <span class="op">=</span> pm.CustomDist(</span>
<span id="cb104-22"><a href="#cb104-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">"C_wd"</span>,</span>
<span id="cb104-23"><a href="#cb104-23" aria-hidden="true" tabindex="-1"></a>        nu,</span>
<span id="cb104-24"><a href="#cb104-24" aria-hidden="true" tabindex="-1"></a>        linear_predictor,</span>
<span id="cb104-25"><a href="#cb104-25" aria-hidden="true" tabindex="-1"></a>        sigma,</span>
<span id="cb104-26"><a href="#cb104-26" aria-hidden="true" tabindex="-1"></a>        observed<span class="op">=</span>y_obs,</span>
<span id="cb104-27"><a href="#cb104-27" aria-hidden="true" tabindex="-1"></a>        shape<span class="op">=</span>linear_predictor.shape,</span>
<span id="cb104-28"><a href="#cb104-28" aria-hidden="true" tabindex="-1"></a>        dist<span class="op">=</span>log_student_t,</span>
<span id="cb104-29"><a href="#cb104-29" aria-hidden="true" tabindex="-1"></a>        class_name<span class="op">=</span><span class="st">"LogStudentT"</span>,</span>
<span id="cb104-30"><a href="#cb104-30" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb104-31"><a href="#cb104-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Monkey patching for textual representation until this is solved in PyMC, for graphviz</span></span>
<span id="cb104-32"><a href="#cb104-32" aria-hidden="true" tabindex="-1"></a>    llike.owner.op._print_name <span class="op">=</span> (<span class="st">"LogStudentT"</span>, <span class="st">"</span><span class="ch">\\</span><span class="st">operatorname</span><span class="sc">{LogStudentT}</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, sample each model and then compute the log-likelihood at each data point. Check the docstring for <code>pm.compute_log_likelihood</code>. This used to be done automatically by <code>pm.sample</code>, but it can spike memory usage and isn’t necessary unless you’re doing model comparison.</p>
<div id="46df297a-c4dd-478f-adda-4ee58c0f8b8f" class="cell" data-execution_count="159">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> model1:</span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>    idata1 <span class="op">=</span> pm.sample()</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>    pm.compute_log_likelihood(idata1)</span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> model2:</span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a>    idata2 <span class="op">=</span> pm.sample()</span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a>    pm.compute_log_likelihood(idata2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [c0, c1, sigma]</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c4847a28dc7a4fa09cb98be36ac67356","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 20 seconds.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"570d9b61af054bf7af82074018c9b5ec","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [c0, c1, sigma, nu]</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"42dfea5e32ec42a99d7c9614556b2421","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 21 seconds.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2943b58db74a4f6a9cfa5ae7136174c9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
</div>
<p>Then compare the two models using Arviz’s <code>az.compare</code>.</p>
<div id="6ea4ccab-43d9-457b-84c8-a80ccf242af4" class="cell" data-execution_count="164">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>az.compare({<span class="st">"model 1"</span>: idata1, <span class="st">"model 2"</span>: idata2}, ic<span class="op">=</span><span class="st">"loo"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="164">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">rank</th>
<th data-quarto-table-cell-role="th">elpd_loo</th>
<th data-quarto-table-cell-role="th">p_loo</th>
<th data-quarto-table-cell-role="th">elpd_diff</th>
<th data-quarto-table-cell-role="th">weight</th>
<th data-quarto-table-cell-role="th">se</th>
<th data-quarto-table-cell-role="th">dse</th>
<th data-quarto-table-cell-role="th">warning</th>
<th data-quarto-table-cell-role="th">scale</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">model 1</td>
<td>0</td>
<td>429.493417</td>
<td>2.623743</td>
<td>0.000000</td>
<td>1.0</td>
<td>6.910277</td>
<td>0.000000</td>
<td>False</td>
<td>log</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">model 2</td>
<td>1</td>
<td>428.640303</td>
<td>2.722466</td>
<td>0.853114</td>
<td>0.0</td>
<td>7.068649</td>
<td>0.311322</td>
<td>False</td>
<td>log</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>The best model is model 1, though it’s close. It prefers the model with the normal likelihood. This is a good result, because we used a normal likelihood to simulate this data! This is from the docstring of <code>az.compare</code>.</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>Returns</span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a><span class="op">-------</span></span>
<span id="cb111-3"><a href="#cb111-3" aria-hidden="true" tabindex="-1"></a>A DataFrame, ordered <span class="im">from</span> best to worst model (measured by the ELPD).</span>
<span id="cb111-4"><a href="#cb111-4" aria-hidden="true" tabindex="-1"></a>The index reflects the key <span class="cf">with</span> which the models are passed to this function. The columns are:</span>
<span id="cb111-5"><a href="#cb111-5" aria-hidden="true" tabindex="-1"></a>rank: The rank<span class="op">-</span>order of the models. <span class="dv">0</span> <span class="kw">is</span> the best.</span>
<span id="cb111-6"><a href="#cb111-6" aria-hidden="true" tabindex="-1"></a>elpd: ELPD estimated either using (PSIS<span class="op">-</span>LOO<span class="op">-</span>CV `elpd_loo` <span class="kw">or</span> WAIC `elpd_waic`).</span>
<span id="cb111-7"><a href="#cb111-7" aria-hidden="true" tabindex="-1"></a>    Higher ELPD indicates higher out<span class="op">-</span>of<span class="op">-</span>sample predictive fit (<span class="st">"better"</span> model).</span>
<span id="cb111-8"><a href="#cb111-8" aria-hidden="true" tabindex="-1"></a>    If `scale` <span class="kw">is</span> `deviance` <span class="kw">or</span> `negative_log` smaller values indicates</span>
<span id="cb111-9"><a href="#cb111-9" aria-hidden="true" tabindex="-1"></a>    higher out<span class="op">-</span>of<span class="op">-</span>sample predictive fit (<span class="st">"better"</span> model).</span>
<span id="cb111-10"><a href="#cb111-10" aria-hidden="true" tabindex="-1"></a>pIC: Estimated effective number of parameters.</span>
<span id="cb111-11"><a href="#cb111-11" aria-hidden="true" tabindex="-1"></a>elpd_diff: The difference <span class="kw">in</span> ELPD between two models.</span>
<span id="cb111-12"><a href="#cb111-12" aria-hidden="true" tabindex="-1"></a>    If more than two models are compared, the difference <span class="kw">is</span> computed relative to the</span>
<span id="cb111-13"><a href="#cb111-13" aria-hidden="true" tabindex="-1"></a>    top<span class="op">-</span>ranked model, that always has a elpd_diff of <span class="fl">0.</span></span>
<span id="cb111-14"><a href="#cb111-14" aria-hidden="true" tabindex="-1"></a>weight: Relative weight <span class="cf">for</span> each model.</span>
<span id="cb111-15"><a href="#cb111-15" aria-hidden="true" tabindex="-1"></a>    This can be loosely interpreted <span class="im">as</span> the probability of each model (among the compared model)</span>
<span id="cb111-16"><a href="#cb111-16" aria-hidden="true" tabindex="-1"></a>    given the data. By default the uncertainty <span class="kw">in</span> the weights estimation <span class="kw">is</span> considered using</span>
<span id="cb111-17"><a href="#cb111-17" aria-hidden="true" tabindex="-1"></a>    Bayesian bootstrap.</span>
<span id="cb111-18"><a href="#cb111-18" aria-hidden="true" tabindex="-1"></a>SE: Standard error of the ELPD estimate.</span>
<span id="cb111-19"><a href="#cb111-19" aria-hidden="true" tabindex="-1"></a>    If method <span class="op">=</span> BB<span class="op">-</span>pseudo<span class="op">-</span>BMA these values are estimated using Bayesian bootstrap.</span>
<span id="cb111-20"><a href="#cb111-20" aria-hidden="true" tabindex="-1"></a>dSE: Standard error of the difference <span class="kw">in</span> ELPD between each model <span class="kw">and</span> the top<span class="op">-</span>ranked model.</span>
<span id="cb111-21"><a href="#cb111-21" aria-hidden="true" tabindex="-1"></a>    It<span class="st">'s always 0 for the top-ranked model.</span></span>
<span id="cb111-22"><a href="#cb111-22" aria-hidden="true" tabindex="-1"></a><span class="er">warning: A value of 1 indicates that the computation of the ELPD may not be reliable.</span></span>
<span id="cb111-23"><a href="#cb111-23" aria-hidden="true" tabindex="-1"></a>    This could be indication of WAIC<span class="op">/</span>LOO starting to fail see</span>
<span id="cb111-24"><a href="#cb111-24" aria-hidden="true" tabindex="-1"></a>    http:<span class="op">//</span>arxiv.org<span class="op">/</span><span class="bu">abs</span><span class="op">/</span><span class="fl">1507.04544</span> <span class="cf">for</span> details.</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>